{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Implementation of Monocular Depth Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda enabled on device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Set Device\n",
    "    torch.cuda.set_device(0)\n",
    "    print(\"Cuda enabled on device: {}\".format(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing depthnet.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile depthnet.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "class DepthNet(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, norm_layer=nn.BatchNorm2d):\n",
    "        super(DepthNet, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        use_bias = True\n",
    "\n",
    "        # Conv1\n",
    "        model1=[nn.Conv2d(input_nc, 64, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[norm_layer(64),]\n",
    "        # add a subsampling operation (in self.forward())\n",
    "\n",
    "        # Conv2\n",
    "        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[norm_layer(128),]\n",
    "        # add a subsampling layer operation (in self.forward())\n",
    "\n",
    "        # Conv3\n",
    "        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[norm_layer(256),]\n",
    "        # add a subsampling layer operation\n",
    "\n",
    "        # Conv4\n",
    "        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[norm_layer(512),]\n",
    "\n",
    "        # Conv5\n",
    "        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[norm_layer(512),]\n",
    "\n",
    "        # Conv6\n",
    "        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[norm_layer(512),]\n",
    "\n",
    "        # Conv7\n",
    "        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[norm_layer(512),]\n",
    "\n",
    "        # Conv7\n",
    "        model8up=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=use_bias)]\n",
    "        model3short8=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "\n",
    "        model8=[nn.ReLU(True),]\n",
    "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "        model8+=[norm_layer(256),]\n",
    "\n",
    "        # Conv9\n",
    "        model9up=[nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=use_bias),]\n",
    "        model2short9=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        # add the two feature maps above        \n",
    "\n",
    "        model9=[nn.ReLU(True),]\n",
    "        model9+=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        model9+=[nn.ReLU(True),]\n",
    "        model9+=[norm_layer(128),]\n",
    "\n",
    "        # Conv10\n",
    "        model10up=[nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=use_bias),]\n",
    "        model1short10=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "        # add the two feature maps above\n",
    "\n",
    "        model10=[nn.ReLU(True),]\n",
    "        model10+=[nn.Conv2d(128, 128, kernel_size=3, dilation=1, stride=1, padding=1, bias=use_bias),]\n",
    "        model10+=[nn.LeakyReLU(negative_slope=.2),]\n",
    "\n",
    "        # Depth Map Regression Output\n",
    "        model_out=[nn.Conv2d(128, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=use_bias),]\n",
    "        model_out+=[nn.ReLU(True),] # Depth should be in [0, +inf)\n",
    "\n",
    "        self.model1 = nn.Sequential(*model1)\n",
    "        self.model2 = nn.Sequential(*model2)\n",
    "        self.model3 = nn.Sequential(*model3)\n",
    "        self.model4 = nn.Sequential(*model4)\n",
    "        self.model5 = nn.Sequential(*model5)\n",
    "        self.model6 = nn.Sequential(*model6)\n",
    "        self.model7 = nn.Sequential(*model7)\n",
    "        self.model8up = nn.Sequential(*model8up)\n",
    "        self.model8 = nn.Sequential(*model8)\n",
    "        self.model9up = nn.Sequential(*model9up)\n",
    "        self.model9 = nn.Sequential(*model9)\n",
    "        self.model10up = nn.Sequential(*model10up)\n",
    "        self.model10 = nn.Sequential(*model10)\n",
    "        self.model3short8 = nn.Sequential(*model3short8)\n",
    "        self.model2short9 = nn.Sequential(*model2short9)\n",
    "        self.model1short10 = nn.Sequential(*model1short10)\n",
    "\n",
    "        self.model_class = nn.Sequential(*model_class)\n",
    "        self.model_out = nn.Sequential(*model_out)\n",
    "\n",
    "        self.upsample4 = nn.Sequential(*[nn.Upsample(scale_factor=4, mode='nearest'),])\n",
    "        self.softmax = nn.Sequential(*[nn.Softmax(dim=1),])\n",
    "\n",
    "    def forward(self, input_A):\n",
    "#         conv1_2 = self.model1(torch.cat((input_A,input_B,mask_B),dim=1))\n",
    "        conv1_2 = self.model1(input_A)\n",
    "        conv2_2 = self.model2(conv1_2[:,:,::2,::2]) # downsample\n",
    "        conv3_3 = self.model3(conv2_2[:,:,::2,::2]) # downsample\n",
    "        conv4_3 = self.model4(conv3_3[:,:,::2,::2]) # downsample\n",
    "        conv5_3 = self.model5(conv4_3)\n",
    "        conv6_3 = self.model6(conv5_3)\n",
    "        conv7_3 = self.model7(conv6_3)\n",
    "        conv8_up = self.model8up(conv7_3) + self.model3short8(conv3_3) # Shortcut\n",
    "        conv8_3 = self.model8(conv8_up)\n",
    "        conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2) # Shortcut\n",
    "        conv9_3 = self.model9(conv9_up)\n",
    "        conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2) # Shortcut\n",
    "        conv10_2 = self.model10(conv10_up)\n",
    "        out_reg = self.model_out(conv10_2)\n",
    "\n",
    "        return out_reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "# Load NYU Depth v2 Training split\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import csv, numpy as np\n",
    "import os\n",
    "import OpenEXR as exr, Imath\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_depth_file_png(filedir, depthfile):\n",
    "    \"\"\"\n",
    "    filedir, depthfile - path to preprocessed depth image file in png format.\n",
    "    n\n",
    "    Returns the image data in an np.array.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def read_rgb_file_jpg(filedir, rgbfile):\n",
    "    \"\"\"\n",
    "    filedir, rgbfile - path to preprocessed rgb image file in pgm format.\n",
    "    \n",
    "    Returns the image data in an np.array.\n",
    "    \"\"\"\n",
    "    return Image.open(os.path.join(filedir, rgbfile))\n",
    "\n",
    "class DepthDataset(Dataset):\n",
    "    \"\"\"Class for reading and storing image and depth data together.\n",
    "    \n",
    "    Designed for:\n",
    "    The NYU Depth v2 Dataset\n",
    "    https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html\n",
    "    \"\"\"\n",
    "    def __init__(self, images_and_depth_maps, load_image, load_depth_map):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        images : list of (string, string)\n",
    "            list of (depth_map_path, rgb_path) filepaths to depth maps and their rgb images.\n",
    "        load_depth_map : function\n",
    "            the function for loading this particular kind of depth_map\n",
    "        load_rgb : function\n",
    "            the function for loading this particular kind of image.\n",
    "        \"\"\"\n",
    "        super(DepthDataset, self).__init__()\n",
    "        self.update_entries(images_and_depth_maps, load_image, load_depth_map)\n",
    "        \n",
    "        \n",
    "    def update_entries(self, images_and_depth_maps, load_image, load_depth_map):\n",
    "        \"\"\"Refresh the dataset without reloading the images\"\"\"\n",
    "        self.dataEntries = []\n",
    "        self.namesToImages = {}\n",
    "        with open(csvfile, \"r\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for entry in reader:\n",
    "                self.dataEntries.append(entry)\n",
    "                # Add the full image to the dict if not already included.\n",
    "                if entry[\"name\"] not in self.namesToImages:\n",
    "                    print(\"loading {}\".format(entry[\"name\"]))\n",
    "                    # Need to read the image into the dictionary\n",
    "                    if entry[\"type\"] == \"exr\":\n",
    "                        filepath = os.path.join(entry[\"dir\"], entry[\"name\"])\n",
    "                        self.namesToImages[entry[\"name\"]] = readEXRImage(filepath, self.channelrange)\n",
    "                    elif entry[\"type\"] == \"png\":\n",
    "                        self.namesToImages[entry[\"name\"]] = readPNGImage(entry[\"dir\"], entry[\"name\"],\n",
    "                                                                           self.channelrange,\n",
    "                                                                           self.minwavelength,\n",
    "                                                                           self.maxwavelength)\n",
    "                    else:\n",
    "                        raise ValueError(\"Invalid entry at row {} - Cannot load data of type '{}'.\".format(idx, dtype))\n",
    "                    print(\"\\tSize: {} bytes.\".format(self.namesToImages[entry[\"name\"]].nbytes))\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.dataEntries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Includes basic data augmentation:\n",
    "        - Flipping\n",
    "        TODO:\n",
    "        - Cropping?\n",
    "        - Hue shifts?\n",
    "        \"\"\"\n",
    "        entry = self.dataEntries[idx]\n",
    "        image = self.namesToImages[entry[\"name\"]]\n",
    "        side = int(entry[\"side\"])\n",
    "        scale = float(entry[\"scale\"])\n",
    "        i = int(entry[\"row\"])\n",
    "        j = int(entry[\"col\"])\n",
    "        shape = (int(side/scale),\n",
    "                 int(side/scale)\n",
    "                )\n",
    "        patch = image[:, i:i+shape[0], j:j+shape[0]]\n",
    "        # Flip if necessary:\n",
    "        if entry[\"flip\"]:\n",
    "            patch = np.flip(patch, axis=3) # Horizontal flip\n",
    "\n",
    "        # Convert to Torch tensor and return\n",
    "        out = torch.Tensor(patch.copy()).type(dtype).cpu()\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Net\n",
    "model = DepthNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# Load data\n",
    "with torch.cuda.device(0):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
