{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Implementation of Monocular Depth Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda enabled on device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Set Device\n",
    "    torch.cuda.set_device(0)\n",
    "    print(\"Cuda enabled on device: {}\".format(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile depthnet.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from collections import OrderedDict\n",
    "\n",
    "def create_sublayer_dict(input_nc, output_nc, layer_index, nconvs, norm_layer, **conv_kwargs):\n",
    "    sublayer=OrderedDict()\n",
    "    j = 0\n",
    "    sublayer.update({\"conv{}_{}\".format(layer_index, j): nn.Conv2d(input_nc, output_nc, **conv_kwargs)})\n",
    "    j += 1\n",
    "    sublayer.update({\"relu{}_{}\".format(layer_index, j): nn.ReLU(True)})\n",
    "    for i in range(nconvs-1):\n",
    "        j += 1\n",
    "        sublayer.update({\"conv{}_{}\".format(layer_index, j): nn.Conv2d(output_nc, output_nc, **conv_kwargs)})\n",
    "        j += 1\n",
    "        sublayer.update({\"relu{}_{}\".format(layer_index, j): nn.ReLU(True)})\n",
    "    if norm_layer:\n",
    "        j += 1\n",
    "        sublayer.update({\"norm{}_{}\".format(layer_index, j): norm_layer(output_nc)})\n",
    "    return sublayer\n",
    "\n",
    "class DepthNet(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, norm_layer=nn.BatchNorm2d):\n",
    "        super(DepthNet, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        use_bias = True\n",
    "\n",
    "        # Conv1\n",
    "#         model1=OrderedDict()\n",
    "#         model1.update({\"conv1_0\": nn.Conv2d(input_nc, 64, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model1.update({\"relu1_1\": nn.ReLU(True)})\n",
    "#         model1.update({\"conv1_2\": nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model1.update({\"relu1_3\": nn.ReLU(True)})\n",
    "#         model1.update({\"norm1_4\": norm_layer(64)})\n",
    "        model1 = create_sublayer_dict(input_nc, 64, 1, 2, norm_layer, \n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "        # add a subsampling operation (in self.forward())\n",
    "\n",
    "        # Conv2\n",
    "#         model2=OrderedDict()\n",
    "#         model2.update({\"conv2_0\": nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model2.update({\"relu2_1\": nn.ReLU(True)})\n",
    "#         model2.update({\"conv2_2\": nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model2.update({\"relu2_3\": nn.ReLU(True)})\n",
    "#         model2.update({\"norm2_4\": norm_layer(128)})\n",
    "        model2 = create_sublayer_dict(64, 128, 2, 2, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "        # add a subsampling layer operation (in self.forward())\n",
    "\n",
    "        # Conv3\n",
    "#         model3=OrderedDict()\n",
    "#         model3.update({\"conv3_0\": nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model3.update({\"relu3_1\": nn.ReLU(True)})\n",
    "#         model3.update({\"conv3_2\": nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model3.update({\"relu3_3\": nn.ReLU(True)})\n",
    "#         model3.update({\"conv3_4\": nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model3.update({\"relu3_5\": nn.ReLU(True)})\n",
    "#         model3.update({\"norm3_6\": norm_layer(256)})\n",
    "        model3 = create_sublayer_dict(128, 256, 3, 3, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "        # add a subsampling layer operation\n",
    "\n",
    "        # Conv4\n",
    "#         model4=OrderedDict()\n",
    "#         model4.update({\"conv4_0\": nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model4.update({\"relu4_1\": nn.ReLU(True)})\n",
    "#         model4.update({\"conv4_2\": nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model4.update({\"relu4_3\": nn.ReLU(True)})\n",
    "#         model4.update({\"conv4_4\": nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias)})\n",
    "#         model4.update({\"relu4_5\": nn.ReLU(True)})\n",
    "#         model4.update({\"norm4_6\": norm_layer(512)})\n",
    "        model4 = create_sublayer_dict(256, 512, 4, 3, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "\n",
    "        # Conv5\n",
    "#         model5=OrderedDict()\n",
    "#         model5.update({\"conv5_0\":nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias)})\n",
    "#         model5+=[nn.ReLU(True),]\n",
    "#         model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "#         model5+=[nn.ReLU(True),]\n",
    "#         model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "#         model5+=[nn.ReLU(True),]\n",
    "#         model5+=[norm_layer(512),]\n",
    "        model5 = create_sublayer_dict(512, 512, 5, 3, norm_layer,\n",
    "                                      kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias)\n",
    "\n",
    "        # Conv6\n",
    "#         model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "#         model6+=[nn.ReLU(True),]\n",
    "#         model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "#         model6+=[nn.ReLU(True),]\n",
    "#         model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias),]\n",
    "#         model6+=[nn.ReLU(True),]\n",
    "#         model6+=[norm_layer(512),]\n",
    "        model6 = create_sublayer_dict(512, 512, 6, 3, norm_layer,\n",
    "                                      kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias)\n",
    "\n",
    "        # Conv7\n",
    "#         model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "#         model7+=[nn.ReLU(True),]\n",
    "#         model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "#         model7+=[nn.ReLU(True),]\n",
    "#         model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "#         model7+=[nn.ReLU(True),]\n",
    "#         model7+=[norm_layer(512),]\n",
    "        model7 = create_sublayer_dict(512, 512, 7, 3, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "\n",
    "        # Conv7\n",
    "        model8up=OrderedDict([(\"convt8_up\", \n",
    "                               nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=use_bias))]\n",
    "                            )\n",
    "        model3short8=OrderedDict([(\"conv3short8\",\n",
    "                                   nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias))]\n",
    "                                )\n",
    "\n",
    "        model8=OrderedDict([(\"relu8_pre\", nn.ReLU(True))])\n",
    "#         model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "#         model8+=[nn.ReLU(True),]\n",
    "#         model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "#         model8+=[nn.ReLU(True),]\n",
    "#         model8+=[norm_layer(256),]\n",
    "        model8.update(create_sublayer_dict(256, 256, 8, 2, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias))\n",
    "\n",
    "        # Conv9\n",
    "        model9up=OrderedDict([(\"convt9_up\", \n",
    "                               nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=use_bias))]\n",
    "                            )\n",
    "        model2short9=OrderedDict([(\"conv2short9\",\n",
    "                                   nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias))]\n",
    "                                )\n",
    "        # add the two feature maps above        \n",
    "\n",
    "        model9=OrderedDict([(\"relu9_pre\", nn.ReLU(True))])\n",
    "#         model9+=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias),]\n",
    "#         model9+=[nn.ReLU(True),]\n",
    "#         model9+=[norm_layer(128),]\n",
    "        model9.update(create_sublayer_dict(128, 128, 9, 1, norm_layer,\n",
    "                                           kernel_size=3, stride=1, padding=1, bias=use_bias))\n",
    "\n",
    "        # Conv10\n",
    "        model10up=OrderedDict([(\"conv10_up\", \n",
    "                               nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=use_bias))]\n",
    "                             )\n",
    "        model1short10=OrderedDict([(\"conv1short10\", \n",
    "                                    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=use_bias))]\n",
    "                                 )\n",
    "        # add the two feature maps above\n",
    "\n",
    "        model10=OrderedDict([(\"relu10_pre\", nn.ReLU(True))])\n",
    "        model10.update({\"conv10_0\": nn.Conv2d(128, 128, kernel_size=3, dilation=1, stride=1, padding=1, bias=use_bias)})\n",
    "        model10.update({\"leakyrelu10_1\": nn.LeakyReLU(negative_slope=.2)})\n",
    "\n",
    "        # Depth Map Regression Output\n",
    "        model_out=OrderedDict([(\"conv_out\",\n",
    "                                nn.Conv2d(128, 1, kernel_size=1, padding=0, dilation=1, stride=1, bias=use_bias))]\n",
    "                             )\n",
    "        model_out.update({\"relu_out\": nn.ReLU(True)}) # Depth should be in [0, +inf)\n",
    "\n",
    "        self.model1 = nn.Sequential(model1)\n",
    "        self.model2 = nn.Sequential(model2)\n",
    "        self.model3 = nn.Sequential(model3)\n",
    "        self.model4 = nn.Sequential(model4)\n",
    "        self.model5 = nn.Sequential(model5)\n",
    "        self.model6 = nn.Sequential(model6)\n",
    "        self.model7 = nn.Sequential(model7)\n",
    "        self.model8up = nn.Sequential(model8up)\n",
    "        self.model8 = nn.Sequential(model8)\n",
    "        self.model9up = nn.Sequential(model9up)\n",
    "        self.model9 = nn.Sequential(model9)\n",
    "        self.model10up = nn.Sequential(model10up)\n",
    "        self.model10 = nn.Sequential(model10)\n",
    "        self.model3short8 = nn.Sequential(model3short8)\n",
    "        self.model2short9 = nn.Sequential(model2short9)\n",
    "        self.model1short10 = nn.Sequential(model1short10)\n",
    "\n",
    "        self.model_out = nn.Sequential(model_out)\n",
    "\n",
    "#         self.upsample4 = nn.Sequential(*[nn.Upsample(scale_factor=4, mode='nearest'),])\n",
    "#         self.softmax = nn.Sequential(*[nn.Softmax(dim=1),])\n",
    "\n",
    "    def forward(self, input_A):\n",
    "#         conv1_2 = self.model1(torch.cat((input_A,input_B,mask_B),dim=1))\n",
    "        conv1_2 = self.model1(input_A)\n",
    "        conv2_2 = self.model2(conv1_2[:,:,::2,::2]) # downsample\n",
    "        conv3_3 = self.model3(conv2_2[:,:,::2,::2]) # downsample\n",
    "        conv4_3 = self.model4(conv3_3[:,:,::2,::2]) # downsample\n",
    "        conv5_3 = self.model5(conv4_3)\n",
    "        conv6_3 = self.model6(conv5_3)\n",
    "        conv7_3 = self.model7(conv6_3)\n",
    "        conv8_up = self.model8up(conv7_3) + self.model3short8(conv3_3) # Shortcut\n",
    "        conv8_3 = self.model8(conv8_up)\n",
    "        conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2) # Shortcut\n",
    "        conv9_3 = self.model9(conv9_up)\n",
    "        conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2) # Shortcut\n",
    "        conv10_2 = self.model10(conv10_up)\n",
    "        out_reg = self.model_out(conv10_2)\n",
    "\n",
    "        return out_reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Dataset #\n",
    "###########\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import csv, numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "class DepthDataset(Dataset):\n",
    "    \"\"\"Class for reading and storing image and depth data together.\n",
    "    \"\"\"\n",
    "    def __init__(self, splitfile, dataDir, transform=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        images : list of (string, string)\n",
    "            list of (depth_map_path, rgb_path) filepaths to depth maps and their rgb images.\n",
    "        load_depth_map : function\n",
    "            the function for loading this particular kind of depth_map\n",
    "        load_rgb : function\n",
    "            the function for loading this particular kind of image.\n",
    "        \"\"\"\n",
    "        super(DepthDataset, self).__init__()\n",
    "        self.dataDir = dataDir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        with open(splitfile, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                self.data.append(line.strip().split(\",\"))\n",
    "#         print(self.data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        depthFile, rgbFile = self.data[idx]\n",
    "        # Extract depth file:\n",
    "        depthImg = Image.open(os.path.join(self.dataDir, depthFile))\n",
    "        # Extract rgb file:\n",
    "        rgbImg = Image.open(os.path.join(self.dataDir, rgbFile))\n",
    "        sample = {\"depth\": depthImg, \"rgb\": rgbImg}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Transforms #\n",
    "##############\n",
    "# for data augmentation\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "\n",
    "        h, w = depth.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        depth = depth[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "        \n",
    "        rgb = rgb[top: top + new_h,\n",
    "                  left: left + new_w]\n",
    "\n",
    "        return {'depth': depth, 'rgb': rgb}\n",
    "\n",
    "class CenterCrop(object):\n",
    "    \"\"\"Center crop the image\n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "        h, w = depth.shape\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = h//2 - new_h//2\n",
    "        bottom = h//2 + new_h//2 + (1 if new_h % 2 else 0)\n",
    "        left = w - new_w//2\n",
    "        right = w + new_w//2 + (1 if new_w % 2 else 0)\n",
    "        \n",
    "        return {\"depth\": depth[top:bottom, left:right],\n",
    "                \"rgb\": rgb[top:bottom, left:right, :]}\n",
    "    \n",
    "class Crop_8(object):\n",
    "    \"\"\"Crop to a size where both dimensions are divisible by 8\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "        new_h, new_w = (depth.shape[0]//8)*8, (depth.shape[1]//8)*8\n",
    "        return {\"depth\": depth[:new_h, :new_w],\n",
    "                \"rgb\": rgb[:new_h, :new_w, :]}\n",
    "        \n",
    "class Crop_small(object):\n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "        h, w = depth.shape[:2]\n",
    "        x = 16\n",
    "        return {\"depth\": depth[h//2-x:h//2+x, w//2-x:w//2+x],\n",
    "                \"rgb\": rgb[h//2-x:h//2+x, w//2-x:w//2+x, :]}\n",
    "\n",
    "class ToFloat(object):\n",
    "    \"\"\"Also parses the depth info for sunrgbd.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        depth = sample['depth']\n",
    "        x = np.asarray(depth, dtype=np.int16)\n",
    "        y = (x >> 3) | (x << 16-3)\n",
    "        z = y.astype(np.float32)/1000\n",
    "        z[z>8.] = 8.\n",
    "        return {\"depth\": z,\n",
    "                \"rgb\": np.asarray(sample['rgb']).astype(np.float32)}\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "#         depth = depth.transpose((2, 0, 1))\n",
    "        rgb = rgb.transpose((2, 0, 1))\n",
    "        return {'depth': torch.from_numpy(depth)[np.newaxis,:,:],\n",
    "                'rgb': torch.from_numpy(rgb)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.cuda as cuda\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os.path\n",
    "# Helper functions\n",
    "\n",
    "#################\n",
    "# Checkpointing #\n",
    "#################\n",
    "def save_checkpoint(state, is_best, filename='/output/checkpoint.pth.tar', always_save=False):\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    if is_best or always_save:\n",
    "        print (\"=> Saving checkpoint to: {}\".format(filename))\n",
    "        torch.save(state, filename)  # save checkpoint\n",
    "    else:\n",
    "        print (\"=> Validation Accuracy did not improve\")\n",
    "\n",
    "##############\n",
    "# Validation #\n",
    "##############\n",
    "def validate(loss, model, val_loader):\n",
    "    \"\"\"Computes the validation error of the model on the validation set.\n",
    "    val_loader should be a DataLoader.\n",
    "    \n",
    "    Returns an ordinary number (i.e. not a tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    it = None\n",
    "    losses = []\n",
    "    for it, data in enumerate(val_loader):\n",
    "        depth = data[\"depth\"].float()\n",
    "        rgb = data[\"rgb\"].float()\n",
    "        if torch.cuda.is_available():\n",
    "            depth = depth.cuda()\n",
    "            rgb = rgb.cuda()\n",
    "        rgb.requires_grad=False\n",
    "        output = model(rgb)\n",
    "        losses.append(loss(output, depth).item())\n",
    "    nbatches = it+1\n",
    "    return sum(losses)/nbatches\n",
    "\n",
    "##################\n",
    "# Viewing Images #\n",
    "##################\n",
    "def save_images(*batches, outputDir, filename):\n",
    "    \"\"\"\n",
    "    Given a list of tensors of size (B, C, H, W) (batch, channels, height, width) torch.Tensor\n",
    "    Saves each entry of the batch as an rgb or grayscale image, depending on how many channels\n",
    "    the image has.\n",
    "    \"\"\"\n",
    "    I = None\n",
    "    trans = transforms.ToPILImage()\n",
    "    for batchnum, batch in enumerate(batches):\n",
    "        if batch.shape[1] == 3:\n",
    "            pass\n",
    "        elif batch.shape[1] == 1:\n",
    "            batch /= torch.max(batch) # normalize to lie in [0, 1]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported number of channels: {}\".format(batch.shape[1]))\n",
    "        batch = batch.type(torch.float32)\n",
    "        for img in range(batch.shape[0]):            \n",
    "            I = trans(batch[img,:,:,:].cpu().detach())\n",
    "            I.save(os.path.join(outputDir, filename + \"_{}_{}.png\".format(batchnum, img)))\n",
    "\n",
    "\n",
    "############\n",
    "# Plotting #\n",
    "############\n",
    "def save_train_val_loss_plots(trainlosses, vallosses, epoch):\n",
    "    # Train loss\n",
    "    fig = plt.figure()\n",
    "    plt.plot(trainlosses)\n",
    "    plt.title(\"Train loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"trainloss_epoch{}.png\".format(epoch))\n",
    "    # Train loss\n",
    "    fig = plt.figure()\n",
    "    plt.plot(trainlosses)\n",
    "    plt.title(\"Val loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Val loss{}.png\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training dataset from data/sunrgbd_nyu/train.txt with size 1159.\n",
      "Loaded dev dataset from data/sunrgbd_nyu/dev.txt with size 145.\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_txt = \"data/sunrgbd_nyu/train.txt\"\n",
    "trainDir = \"data/sunrgbd_nyu\"\n",
    "train = DepthDataset(train_txt, trainDir, \n",
    "                     transform = transforms.Compose([ToFloat(), RandomCrop((400, 320)), ToTensor()])\n",
    "#                      transform=transforms.Compose([ToFloat(), Crop_8(), ToFloat(), ToTensor()])\n",
    "#                      transform=transforms.Compose([ToFloat(), Crop_small(), ToFloat(), ToTensor()])\n",
    "                    )\n",
    "\n",
    "print(\"Loaded training dataset from {} with size {}.\".format(train_txt, len(train)))\n",
    "\n",
    "dev_txt = \"data/sunrgbd_nyu/dev.txt\"\n",
    "devDir = \"data/sunrgbd_nyu\"\n",
    "dev = DepthDataset(dev_txt, devDir, \n",
    "                     transform = transforms.Compose([ToFloat(), CenterCrop((400, 320)), ToTensor()])\n",
    "#                      transform=transforms.Compose([ToFloat(), Crop_8(), ToTensor()])\n",
    "#                      transform=transforms.Compose([ToFloat(), Crop_small(), ToTensor()])\n",
    "                    )\n",
    "print(\"Loaded dev dataset from {} with size {}.\".format(dev_txt, len(dev)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1.conv1_0.weight\n",
      "model1.conv1_2.weight\n",
      "model1.norm1_4.weight\n",
      "model2.conv2_0.weight\n",
      "model2.conv2_2.weight\n",
      "model2.norm2_4.weight\n",
      "model3.conv3_0.weight\n",
      "model3.conv3_2.weight\n",
      "model3.conv3_4.weight\n",
      "model3.norm3_6.weight\n",
      "model4.conv4_0.weight\n",
      "model4.conv4_2.weight\n",
      "model4.conv4_4.weight\n",
      "model4.norm4_6.weight\n",
      "model5.conv5_0.weight\n",
      "model5.conv5_2.weight\n",
      "model5.conv5_4.weight\n",
      "model5.norm5_6.weight\n",
      "model6.conv6_0.weight\n",
      "model6.conv6_2.weight\n",
      "model6.conv6_4.weight\n",
      "model6.norm6_6.weight\n",
      "model7.conv7_0.weight\n",
      "model7.conv7_2.weight\n",
      "model7.conv7_4.weight\n",
      "model7.norm7_6.weight\n",
      "model8up.convt8_up.weight\n",
      "model8.conv8_0.weight\n",
      "model8.conv8_2.weight\n",
      "model8.norm8_4.weight\n",
      "model9up.convt9_up.weight\n",
      "model9.conv9_0.weight\n",
      "model9.norm9_2.weight\n",
      "model10up.conv10_up.weight\n",
      "model10.conv10_0.weight\n",
      "model3short8.conv3short8.weight\n",
      "model2short9.conv2short9.weight\n",
      "model1short10.conv1short10.weight\n",
      "model_out.conv_out.weight\n",
      "loaded checkpointfile: None\n",
      "start_epoch: 0\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "batch_size: 10\n",
      "num_epochs: 30\n",
      "learning rate (initial): 0.001\n"
     ]
    }
   ],
   "source": [
    "# Set up training.\n",
    "import torch.optim as optim\n",
    "\n",
    "checkpointfile = None\n",
    "# lam = 1e-8 # Weight decay parameter for L2 regularization\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 30\n",
    "batch_size = 10\n",
    "\n",
    "# Build model and loss\n",
    "# Hyperparameters\n",
    "input_nc = 3\n",
    "output_nc = 1\n",
    "\n",
    "model = DepthNet(input_nc, output_nc)\n",
    "\n",
    "#################\n",
    "# Loss function #\n",
    "#################\n",
    "\n",
    "def berhu_loss(prediction, target):\n",
    "    diff = prediction - target\n",
    "    threshold = 0.2*torch.max(torch.abs(prediction - target))\n",
    "    c = threshold.detach()\n",
    "    l2_part = torch.sum((diff**2 + c**2))/(2*c)\n",
    "    l1_part = torch.sum(torch.abs(diff))\n",
    "    return l1_part+l2_part\n",
    "\n",
    "# loss = nn.SmoothL1Loss()\n",
    "# loss = berhu_loss\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    loss.cuda()\n",
    "\n",
    "# Checkpointing\n",
    "if checkpointfile is not None:\n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(checkpointfile)\n",
    "    else:\n",
    "        # Load GPU model on CPU\n",
    "        checkpoint = torch.load(checkpointfile,\n",
    "                                map_location=lambda storage,\n",
    "                                loc: storage)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
    "    trainlosses = checkpoint['trainlosses']\n",
    "#     vallosses = checkpoint['vallosses']\n",
    "    print(\"=> loaded checkpoint '{}' (trained for {} epochs)\".format(resume_weights, checkpoint['epoch']))\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_loss = torch.FloatTensor([float('inf')])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    trainlosses = []\n",
    "    vallosses = []\n",
    "    # Initialize weights:\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"conv\" in name and \"weight\" in name:\n",
    "            print(name)\n",
    "            nn.init.xavier_normal_(param)\n",
    "        if \"norm\" in name and \"weight\" in name:\n",
    "            print(name)\n",
    "            nn.init.constant_(param, 1)\n",
    "        elif \"bias\" in name:\n",
    "            nn.init.constant_(param, 0)\n",
    "            \n",
    "# Scheduler\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 20], gamma=0.1)\n",
    "\n",
    "# Print summary of setup:\n",
    "print(\"loaded checkpointfile: {}\".format(checkpointfile))\n",
    "print(\"start_epoch: {}\".format(start_epoch))\n",
    "print(\"optimizer: {}\".format(optimizer))\n",
    "print(\"batch_size: {}\".format(batch_size))\n",
    "print(\"num_epochs: {}\".format(num_epochs))\n",
    "print(\"learning rate (initial): {}\".format(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "\titeration: 0\ttrain loss: 6.660920143127441\n",
      "\titeration: 10\ttrain loss: 5.001108646392822\n",
      "\titeration: 20\ttrain loss: 4.368201732635498\n",
      "\titeration: 30\ttrain loss: 4.636993885040283\n",
      "\titeration: 40\ttrain loss: 4.026307582855225\n",
      "\titeration: 50\ttrain loss: 4.151325702667236\n",
      "\titeration: 60\ttrain loss: 2.713653564453125\n",
      "\titeration: 70\ttrain loss: 7.817407131195068\n",
      "\titeration: 80\ttrain loss: 7.717471122741699\n",
      "\titeration: 90\ttrain loss: 7.311159610748291\n",
      "\titeration: 100\ttrain loss: 5.854341983795166\n",
      "\titeration: 110\ttrain loss: 3.552532911300659\n",
      "End epoch 0\tval loss: 4.129573836408812\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_0.pth.tar\n",
      "epoch: 1\n",
      "\titeration: 0\ttrain loss: 3.346029758453369\n",
      "\titeration: 10\ttrain loss: 4.425172328948975\n",
      "\titeration: 20\ttrain loss: 3.7099063396453857\n",
      "\titeration: 30\ttrain loss: 4.798088073730469\n",
      "\titeration: 40\ttrain loss: 4.025942325592041\n",
      "\titeration: 50\ttrain loss: 6.871330261230469\n",
      "\titeration: 60\ttrain loss: 4.025509357452393\n",
      "\titeration: 70\ttrain loss: 5.019134521484375\n",
      "\titeration: 80\ttrain loss: 4.856333255767822\n",
      "\titeration: 90\ttrain loss: 5.407094955444336\n",
      "\titeration: 100\ttrain loss: 3.094499111175537\n",
      "\titeration: 110\ttrain loss: 2.980513334274292\n",
      "End epoch 1\tval loss: 3.961402017494728\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_1.pth.tar\n",
      "epoch: 2\n",
      "\titeration: 0\ttrain loss: 3.5184223651885986\n",
      "\titeration: 10\ttrain loss: 4.299950122833252\n",
      "\titeration: 20\ttrain loss: 5.570438861846924\n",
      "\titeration: 30\ttrain loss: 5.981224536895752\n",
      "\titeration: 40\ttrain loss: 2.164433479309082\n",
      "\titeration: 50\ttrain loss: 5.020866870880127\n",
      "\titeration: 60\ttrain loss: 3.0832154750823975\n",
      "\titeration: 70\ttrain loss: 3.827157735824585\n",
      "\titeration: 80\ttrain loss: 4.2246809005737305\n",
      "\titeration: 90\ttrain loss: 3.7954750061035156\n",
      "\titeration: 100\ttrain loss: 5.472465991973877\n",
      "\titeration: 110\ttrain loss: 3.143998146057129\n",
      "End epoch 2\tval loss: 3.9133190533210493\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_2.pth.tar\n",
      "epoch: 3\n",
      "\titeration: 0\ttrain loss: 4.254985332489014\n",
      "\titeration: 10\ttrain loss: 3.676126480102539\n",
      "\titeration: 20\ttrain loss: 5.090383529663086\n",
      "\titeration: 30\ttrain loss: 5.6534576416015625\n",
      "\titeration: 40\ttrain loss: 6.3095598220825195\n",
      "\titeration: 50\ttrain loss: 2.424283266067505\n",
      "\titeration: 60\ttrain loss: 3.7251954078674316\n",
      "\titeration: 70\ttrain loss: 3.192074775695801\n",
      "\titeration: 80\ttrain loss: 5.033029556274414\n",
      "\titeration: 90\ttrain loss: 3.517352819442749\n",
      "\titeration: 100\ttrain loss: 3.729282855987549\n",
      "\titeration: 110\ttrain loss: 5.552684783935547\n",
      "End epoch 3\tval loss: 3.961052524632421\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_3.pth.tar\n",
      "epoch: 4\n",
      "\titeration: 0\ttrain loss: 6.055174827575684\n",
      "\titeration: 10\ttrain loss: 2.9574713706970215\n",
      "\titeration: 20\ttrain loss: 4.571086883544922\n",
      "\titeration: 30\ttrain loss: 4.304720401763916\n",
      "\titeration: 40\ttrain loss: 2.525667428970337\n",
      "\titeration: 50\ttrain loss: 2.7460594177246094\n",
      "\titeration: 60\ttrain loss: 2.5081896781921387\n",
      "\titeration: 70\ttrain loss: 4.809781074523926\n",
      "\titeration: 80\ttrain loss: 3.48091721534729\n",
      "\titeration: 90\ttrain loss: 6.799954891204834\n",
      "\titeration: 100\ttrain loss: 4.391403675079346\n",
      "\titeration: 110\ttrain loss: 4.976490020751953\n",
      "End epoch 4\tval loss: 3.9212175535744636\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_4.pth.tar\n",
      "epoch: 5\n",
      "\titeration: 0\ttrain loss: 3.167602062225342\n",
      "\titeration: 10\ttrain loss: 4.900933742523193\n",
      "\titeration: 20\ttrain loss: 3.342240333557129\n",
      "\titeration: 30\ttrain loss: 4.416103839874268\n",
      "\titeration: 40\ttrain loss: 6.892821788787842\n",
      "\titeration: 50\ttrain loss: 4.2475409507751465\n",
      "\titeration: 60\ttrain loss: 4.281147480010986\n",
      "\titeration: 70\ttrain loss: 3.5267372131347656\n",
      "\titeration: 80\ttrain loss: 2.7315075397491455\n",
      "\titeration: 90\ttrain loss: 3.513810157775879\n",
      "\titeration: 100\ttrain loss: 6.49811315536499\n",
      "\titeration: 110\ttrain loss: 4.416572093963623\n",
      "End epoch 5\tval loss: 4.01318745160925\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_5.pth.tar\n",
      "epoch: 6\n",
      "\titeration: 0\ttrain loss: 2.866103172302246\n",
      "\titeration: 10\ttrain loss: 3.0048186779022217\n",
      "\titeration: 20\ttrain loss: 6.160286903381348\n",
      "\titeration: 30\ttrain loss: 4.271943092346191\n",
      "\titeration: 40\ttrain loss: 3.3102269172668457\n",
      "\titeration: 50\ttrain loss: 3.470093011856079\n",
      "\titeration: 60\ttrain loss: 3.5593059062957764\n",
      "\titeration: 70\ttrain loss: 2.2806265354156494\n",
      "\titeration: 80\ttrain loss: 5.809225559234619\n",
      "\titeration: 90\ttrain loss: 4.746524333953857\n",
      "\titeration: 100\ttrain loss: 4.392266750335693\n",
      "\titeration: 110\ttrain loss: 4.074796199798584\n",
      "End epoch 6\tval loss: 4.100767589848617\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_6.pth.tar\n",
      "epoch: 7\n",
      "\titeration: 0\ttrain loss: 4.981469631195068\n",
      "\titeration: 10\ttrain loss: 3.9955215454101562\n",
      "\titeration: 20\ttrain loss: 4.066951751708984\n",
      "\titeration: 30\ttrain loss: 4.012805461883545\n",
      "\titeration: 40\ttrain loss: 0.985845685005188\n",
      "\titeration: 50\ttrain loss: 4.591712474822998\n",
      "\titeration: 60\ttrain loss: 6.114906311035156\n",
      "\titeration: 70\ttrain loss: 4.259087562561035\n",
      "\titeration: 80\ttrain loss: 5.095202922821045\n",
      "\titeration: 90\ttrain loss: 7.225887298583984\n",
      "\titeration: 100\ttrain loss: 4.069239616394043\n",
      "\titeration: 110\ttrain loss: 3.332054376602173\n",
      "End epoch 7\tval loss: 3.9435098212340782\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_7.pth.tar\n",
      "epoch: 8\n",
      "\titeration: 0\ttrain loss: 3.316434860229492\n",
      "\titeration: 10\ttrain loss: 5.239831924438477\n",
      "\titeration: 20\ttrain loss: 2.6768112182617188\n",
      "\titeration: 30\ttrain loss: 3.5038695335388184\n",
      "\titeration: 40\ttrain loss: 4.33671236038208\n",
      "\titeration: 50\ttrain loss: 5.041930675506592\n",
      "\titeration: 60\ttrain loss: 2.9393229484558105\n",
      "\titeration: 70\ttrain loss: 3.5541648864746094\n",
      "\titeration: 80\ttrain loss: 2.0595908164978027\n",
      "\titeration: 90\ttrain loss: 5.486773490905762\n",
      "\titeration: 100\ttrain loss: 4.448118686676025\n",
      "\titeration: 110\ttrain loss: 4.649362564086914\n",
      "End epoch 8\tval loss: 4.053198275894954\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_8.pth.tar\n",
      "epoch: 9\n",
      "\titeration: 0\ttrain loss: 3.6744766235351562\n",
      "\titeration: 10\ttrain loss: 5.568455696105957\n",
      "\titeration: 20\ttrain loss: 4.405655384063721\n",
      "\titeration: 30\ttrain loss: 4.303285598754883\n",
      "\titeration: 40\ttrain loss: 5.331360816955566\n",
      "\titeration: 50\ttrain loss: 5.828115463256836\n",
      "\titeration: 60\ttrain loss: 3.9402964115142822\n",
      "\titeration: 70\ttrain loss: 4.149119853973389\n",
      "\titeration: 80\ttrain loss: 5.557141304016113\n",
      "\titeration: 90\ttrain loss: 4.102991580963135\n",
      "\titeration: 100\ttrain loss: 4.998101234436035\n",
      "\titeration: 110\ttrain loss: 4.851467132568359\n",
      "End epoch 9\tval loss: 4.2210719667632\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_9.pth.tar\n",
      "epoch: 10\n",
      "\titeration: 0\ttrain loss: 3.584120035171509\n",
      "\titeration: 10\ttrain loss: 3.9027340412139893\n",
      "\titeration: 20\ttrain loss: 6.205746173858643\n",
      "\titeration: 30\ttrain loss: 5.262008190155029\n",
      "\titeration: 40\ttrain loss: 5.462308406829834\n",
      "\titeration: 50\ttrain loss: 5.035006999969482\n",
      "\titeration: 60\ttrain loss: 4.863826274871826\n",
      "\titeration: 70\ttrain loss: 3.975368022918701\n",
      "\titeration: 80\ttrain loss: 5.046750545501709\n",
      "\titeration: 90\ttrain loss: 2.0570340156555176\n",
      "\titeration: 100\ttrain loss: 4.147912979125977\n",
      "\titeration: 110\ttrain loss: 3.3462464809417725\n",
      "End epoch 10\tval loss: 3.839804743898326\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_10.pth.tar\n",
      "epoch: 11\n",
      "\titeration: 0\ttrain loss: 4.768127918243408\n",
      "\titeration: 10\ttrain loss: 4.320916652679443\n",
      "\titeration: 20\ttrain loss: 8.142830848693848\n",
      "\titeration: 30\ttrain loss: 2.997443437576294\n",
      "\titeration: 40\ttrain loss: 4.391929626464844\n",
      "\titeration: 50\ttrain loss: 3.4097609519958496\n",
      "\titeration: 60\ttrain loss: 2.836780548095703\n",
      "\titeration: 70\ttrain loss: 2.249518632888794\n",
      "\titeration: 80\ttrain loss: 4.5163140296936035\n",
      "\titeration: 90\ttrain loss: 5.522803783416748\n",
      "\titeration: 100\ttrain loss: 3.5545804500579834\n",
      "\titeration: 110\ttrain loss: 3.5666282176971436\n",
      "End epoch 11\tval loss: 3.903409544763894\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_11.pth.tar\n",
      "epoch: 12\n",
      "\titeration: 0\ttrain loss: 2.0699312686920166\n",
      "\titeration: 10\ttrain loss: 3.802332878112793\n",
      "\titeration: 20\ttrain loss: 4.544655799865723\n",
      "\titeration: 30\ttrain loss: 4.862389087677002\n",
      "\titeration: 40\ttrain loss: 2.811366081237793\n",
      "\titeration: 50\ttrain loss: 4.732064247131348\n",
      "\titeration: 60\ttrain loss: 6.316277980804443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titeration: 70\ttrain loss: 4.5194854736328125\n",
      "\titeration: 80\ttrain loss: 4.56994104385376\n",
      "\titeration: 90\ttrain loss: 3.959199905395508\n",
      "\titeration: 100\ttrain loss: 2.840179681777954\n",
      "\titeration: 110\ttrain loss: 1.8852673768997192\n",
      "End epoch 12\tval loss: 3.964126634186712\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_12.pth.tar\n",
      "epoch: 13\n",
      "\titeration: 0\ttrain loss: 7.416388511657715\n",
      "\titeration: 10\ttrain loss: 3.169062614440918\n",
      "\titeration: 20\ttrain loss: 4.655360698699951\n",
      "\titeration: 30\ttrain loss: 2.8012311458587646\n",
      "\titeration: 40\ttrain loss: 3.263439655303955\n",
      "\titeration: 50\ttrain loss: 3.7320077419281006\n",
      "\titeration: 60\ttrain loss: 3.603193759918213\n",
      "\titeration: 70\ttrain loss: 4.2478532791137695\n",
      "\titeration: 80\ttrain loss: 2.9094114303588867\n",
      "\titeration: 90\ttrain loss: 3.6379082202911377\n",
      "\titeration: 100\ttrain loss: 6.977484226226807\n",
      "\titeration: 110\ttrain loss: 2.7691147327423096\n",
      "End epoch 13\tval loss: 3.8417478758713295\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_13.pth.tar\n",
      "epoch: 14\n",
      "\titeration: 0\ttrain loss: 5.4815239906311035\n",
      "\titeration: 10\ttrain loss: 4.41225528717041\n",
      "\titeration: 20\ttrain loss: 4.547337532043457\n",
      "\titeration: 30\ttrain loss: 3.1419284343719482\n",
      "\titeration: 40\ttrain loss: 3.2894320487976074\n",
      "\titeration: 50\ttrain loss: 2.9279792308807373\n",
      "\titeration: 60\ttrain loss: 4.142637729644775\n",
      "\titeration: 70\ttrain loss: 5.1641764640808105\n",
      "\titeration: 80\ttrain loss: 4.953954696655273\n",
      "\titeration: 90\ttrain loss: 5.030067443847656\n",
      "\titeration: 100\ttrain loss: 2.901207208633423\n",
      "\titeration: 110\ttrain loss: 3.2804110050201416\n",
      "End epoch 14\tval loss: 3.8841932436515547\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_14.pth.tar\n",
      "epoch: 15\n",
      "\titeration: 0\ttrain loss: 3.5290844440460205\n",
      "\titeration: 10\ttrain loss: 3.322927236557007\n",
      "\titeration: 20\ttrain loss: 3.8877480030059814\n",
      "\titeration: 30\ttrain loss: 5.015618801116943\n",
      "\titeration: 40\ttrain loss: 2.604391574859619\n",
      "\titeration: 50\ttrain loss: 4.20010232925415\n",
      "\titeration: 60\ttrain loss: 4.293348789215088\n",
      "\titeration: 70\ttrain loss: 3.8471999168395996\n",
      "\titeration: 80\ttrain loss: 3.6393022537231445\n",
      "\titeration: 90\ttrain loss: 4.5454936027526855\n",
      "\titeration: 100\ttrain loss: 2.8262362480163574\n",
      "\titeration: 110\ttrain loss: 4.359954833984375\n",
      "End epoch 15\tval loss: 4.026066048391934\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_15.pth.tar\n",
      "epoch: 16\n",
      "\titeration: 0\ttrain loss: 3.0241358280181885\n",
      "\titeration: 10\ttrain loss: 3.903066396713257\n",
      "\titeration: 20\ttrain loss: 3.62004017829895\n",
      "\titeration: 30\ttrain loss: 3.212507724761963\n",
      "\titeration: 40\ttrain loss: 4.361793518066406\n",
      "\titeration: 50\ttrain loss: 2.9090065956115723\n",
      "\titeration: 60\ttrain loss: 4.914370536804199\n",
      "\titeration: 70\ttrain loss: 5.402039527893066\n",
      "\titeration: 80\ttrain loss: 2.3108103275299072\n",
      "\titeration: 90\ttrain loss: 4.539098262786865\n",
      "\titeration: 100\ttrain loss: 4.024268627166748\n",
      "\titeration: 110\ttrain loss: 3.1604700088500977\n",
      "End epoch 16\tval loss: 3.988465822976211\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_16.pth.tar\n",
      "epoch: 17\n",
      "\titeration: 0\ttrain loss: 3.0109360218048096\n",
      "\titeration: 10\ttrain loss: 3.1297593116760254\n",
      "\titeration: 20\ttrain loss: 2.9207780361175537\n",
      "\titeration: 30\ttrain loss: 4.504711627960205\n",
      "\titeration: 40\ttrain loss: 4.510486125946045\n",
      "\titeration: 50\ttrain loss: 4.34704065322876\n",
      "\titeration: 60\ttrain loss: 3.2298166751861572\n",
      "\titeration: 70\ttrain loss: 3.2020206451416016\n",
      "\titeration: 80\ttrain loss: 5.619126319885254\n",
      "\titeration: 90\ttrain loss: 4.594921112060547\n",
      "\titeration: 100\ttrain loss: 4.558033466339111\n",
      "\titeration: 110\ttrain loss: 2.9851393699645996\n",
      "End epoch 17\tval loss: 3.923718818302812\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_17.pth.tar\n",
      "epoch: 18\n",
      "\titeration: 0\ttrain loss: 3.908888339996338\n",
      "\titeration: 10\ttrain loss: 5.1490607261657715\n",
      "\titeration: 20\ttrain loss: 2.7674543857574463\n",
      "\titeration: 30\ttrain loss: 4.490987300872803\n",
      "\titeration: 40\ttrain loss: 7.56571102142334\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Run the training #\n",
    "####################\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dev, batch_size=5, shuffle=True, num_workers=1)\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    data = None\n",
    "    output = None\n",
    "    for it, data in enumerate(train_loader):\n",
    "        depth = data[\"depth\"].float()\n",
    "        rgb = data[\"rgb\"].float()\n",
    "#         print('ok')\n",
    "\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            depth = depth.cuda()\n",
    "            rgb = rgb.cuda()\n",
    "        # New batch\n",
    "#         print(rgb.dtype)\n",
    "        scheduler.optimizer.zero_grad()\n",
    "        output = model(rgb)\n",
    "        \n",
    "        # Save the first batch output of every epoch\n",
    "        \n",
    "#         a = list(model.parameters())[0].clone()\n",
    "\n",
    "        trainloss = loss(output, depth)\n",
    "        trainloss.backward()\n",
    "#         print(list(model.parameters())[0].grad)\n",
    "        scheduler.optimizer.step()\n",
    "#         print(depth)\n",
    "#         print(output)\n",
    "#         b = list(model.parameters())[0].clone()\n",
    "\n",
    "        if not (it % 10):\n",
    "            print(\"\\titeration: {}\\ttrain loss: {}\".format(it, trainloss.item()))\n",
    "        trainlosses.append(trainloss.item())\n",
    "        \n",
    "        # TESTING:\n",
    "#         if not ((it + 1) % 5):\n",
    "#             # Stop after 5 batches\n",
    "#             break\n",
    "\n",
    "#         print(torch.equal(a.data, b.data))\n",
    "    # Checkpointing\n",
    "    # Get bool not ByteTensor\"\n",
    "    valloss = validate(loss, model, val_loader)\n",
    "    print(\"End epoch {}\\tval loss: {}\".format(epoch, valloss))\n",
    "    vallosses.append(valloss)\n",
    "\n",
    "    # Save the last batch output of every epoch\n",
    "    save_images(data[\"rgb\"], data[\"depth\"], output, outputDir=\"images\", filename=\"epoch_{}\".format(epoch))\n",
    "    \n",
    "    is_best = bool(trainloss.data.cpu().numpy() < best_loss.numpy())\n",
    "    # Get greater Tensor to keep track best acc\n",
    "    best_loss = torch.FloatTensor(min(trainloss.data.cpu().numpy(), best_loss.numpy()))\n",
    "    # Save checkpoint\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "        'optim_state_dict': optimizer.state_dict(),\n",
    "        'trainlosses': trainlosses,\n",
    "        'vallosses': vallosses\n",
    "    }, is_best, filename=\"checkpoints/checkpoint_epoch_{}.pth.tar\".format(epoch), always_save=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc786100080>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize training loss\n",
    "checkpoint = torch.load(\"checkpoints/checkpoint_epoch_29.pth.tar\")\n",
    "trainlosses = checkpoint['trainlosses']\n",
    "plt.semilogy(trainlosses)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6c6dd09e8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training loss\n",
    "\n",
    "trainlosses = checkpoint['vallosses']\n",
    "plt.semilogy(trainlosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "print(type(rgb))\n",
    "imshow(rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# Load data\n",
    "a = torch.ones(1, requires_grad=True)\n",
    "b = torch.ones(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b\n",
    "c.register_hook(print)\n",
    "s = a**2 + b**2\n",
    "s.register_hook(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = torch.sum(c)\n",
    "e = c.detach()\n",
    "f = torch.sum(s)\n",
    "g = f/e\n",
    "g.backward()\n",
    "# s.backward()\n",
    "# f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
