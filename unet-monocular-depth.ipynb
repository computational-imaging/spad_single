{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Implementation of Monocular Depth Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda enabled on device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Set Device\n",
    "    torch.cuda.set_device(0)\n",
    "    print(\"Cuda enabled on device: {}\".format(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting depthnet/model.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile depthnet/model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from collections import OrderedDict\n",
    "\n",
    "def create_sublayer_dict(input_nc, output_nc, layer_index, nconvs, norm_layer, **conv_kwargs):\n",
    "    sublayer=OrderedDict()\n",
    "    j = 0\n",
    "    sublayer.update({\"conv{}_{}\".format(layer_index, j): nn.Conv2d(input_nc, output_nc, **conv_kwargs)})\n",
    "    j += 1\n",
    "    sublayer.update({\"relu{}_{}\".format(layer_index, j): nn.ReLU(True)})\n",
    "    for i in range(nconvs-1):\n",
    "        j += 1\n",
    "        sublayer.update({\"conv{}_{}\".format(layer_index, j): nn.Conv2d(output_nc, output_nc, **conv_kwargs)})\n",
    "        j += 1\n",
    "        sublayer.update({\"relu{}_{}\".format(layer_index, j): nn.ReLU(True)})\n",
    "    if norm_layer:\n",
    "        j += 1\n",
    "        sublayer.update({\"norm{}_{}\".format(layer_index, j): norm_layer(output_nc)})\n",
    "    return sublayer\n",
    "\n",
    "class DepthNet(nn.Module):\n",
    "    def __init__(self, input_nc=3, output_nc=1, norm_layer=nn.BatchNorm2d):\n",
    "        super(DepthNet, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        use_bias = True\n",
    "\n",
    "        # Conv1\n",
    "        model1 = create_sublayer_dict(input_nc, 32, 1, 2, norm_layer, \n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "        # add a subsampling operation (in self.forward())\n",
    "\n",
    "        # Conv2\n",
    "        model2 = create_sublayer_dict(32, 64, 2, 2, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "        # add a subsampling layer operation (in self.forward())\n",
    "\n",
    "        # Conv3\n",
    "        model3 = create_sublayer_dict(64, 128, 3, 3, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "        # add a subsampling layer operation\n",
    "\n",
    "        # Conv4\n",
    "        model4 = create_sublayer_dict(128, 256, 4, 3, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "\n",
    "        # Conv5\n",
    "        model5 = create_sublayer_dict(256, 256, 5, 3, norm_layer,\n",
    "                                      kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias)\n",
    "\n",
    "        # Conv6\n",
    "        model6 = create_sublayer_dict(256, 256, 6, 3, norm_layer,\n",
    "                                      kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias)\n",
    "\n",
    "        # Conv7\n",
    "        model7 = create_sublayer_dict(256, 256, 7, 3, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "\n",
    "        # Conv7\n",
    "        model8up=OrderedDict([(\"convt8_up\", \n",
    "                               nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=use_bias))]\n",
    "                            )\n",
    "        model3short8=OrderedDict([(\"conv3short8\",\n",
    "                                   nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias))]\n",
    "                                )\n",
    "\n",
    "        model8=OrderedDict([(\"relu8_pre\", nn.ReLU(True))])\n",
    "\n",
    "        model8.update(create_sublayer_dict(128, 128, 8, 2, norm_layer,\n",
    "                                      kernel_size=3, stride=1, padding=1, bias=use_bias))\n",
    "\n",
    "        # Conv9\n",
    "        model9up=OrderedDict([(\"convt9_up\", \n",
    "                               nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=use_bias))]\n",
    "                            )\n",
    "        model2short9=OrderedDict([(\"conv2short9\",\n",
    "                                   nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=use_bias))]\n",
    "                                )\n",
    "        # add the two feature maps above        \n",
    "\n",
    "        model9=OrderedDict([(\"relu9_pre\", nn.ReLU(True))])\n",
    "\n",
    "        model9.update(create_sublayer_dict(64, 64, 9, 1, norm_layer,\n",
    "                                           kernel_size=3, stride=1, padding=1, bias=use_bias))\n",
    "\n",
    "        # Conv10\n",
    "        model10up=OrderedDict([(\"conv10_up\", \n",
    "                               nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1, bias=use_bias))]\n",
    "                             )\n",
    "        model1short10=OrderedDict([(\"conv1short10\", \n",
    "                                    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=use_bias))]\n",
    "                                 )\n",
    "        # add the two feature maps above\n",
    "\n",
    "        model10=OrderedDict([(\"relu10_pre\", nn.ReLU(True))])\n",
    "        model10.update({\"conv10_0\": nn.Conv2d(64, 64, kernel_size=3, dilation=1, stride=1, padding=1, bias=use_bias)})\n",
    "        model10.update({\"leakyrelu10_1\": nn.LeakyReLU(negative_slope=.2)})\n",
    "\n",
    "        # Depth Map Regression Output\n",
    "        model_out=OrderedDict([(\"conv_out\",\n",
    "                                nn.Conv2d(64, 1, kernel_size=1, padding=0, dilation=1, stride=1, bias=use_bias))]\n",
    "                             )\n",
    "        model_out.update({\"relu_out\": nn.ReLU(True)}) # Depth should be in [0, +inf)\n",
    "\n",
    "        self.model1 = nn.Sequential(model1)\n",
    "        self.model2 = nn.Sequential(model2)\n",
    "        self.model3 = nn.Sequential(model3)\n",
    "        self.model4 = nn.Sequential(model4)\n",
    "        self.model5 = nn.Sequential(model5)\n",
    "        self.model6 = nn.Sequential(model6)\n",
    "        self.model7 = nn.Sequential(model7)\n",
    "        self.model8up = nn.Sequential(model8up)\n",
    "        self.model8 = nn.Sequential(model8)\n",
    "        self.model9up = nn.Sequential(model9up)\n",
    "        self.model9 = nn.Sequential(model9)\n",
    "        self.model10up = nn.Sequential(model10up)\n",
    "        self.model10 = nn.Sequential(model10)\n",
    "        self.model3short8 = nn.Sequential(model3short8)\n",
    "        self.model2short9 = nn.Sequential(model2short9)\n",
    "        self.model1short10 = nn.Sequential(model1short10)\n",
    "        self.model_out = nn.Sequential(model_out)\n",
    "\n",
    "    def forward(self, input_A):\n",
    "        conv1_2 = self.model1(input_A)\n",
    "        conv2_2 = self.model2(conv1_2[:,:,::2,::2]) # downsample\n",
    "        conv3_3 = self.model3(conv2_2[:,:,::2,::2]) # downsample\n",
    "        conv4_3 = self.model4(conv3_3[:,:,::2,::2]) # downsample\n",
    "        conv5_3 = self.model5(conv4_3)\n",
    "        conv6_3 = self.model6(conv5_3)\n",
    "        conv7_3 = self.model7(conv6_3)\n",
    "        conv8_up = self.model8up(conv7_3) + self.model3short8(conv3_3) # Shortcut\n",
    "        conv8_3 = self.model8(conv8_up)\n",
    "        conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2) # Shortcut\n",
    "        conv9_3 = self.model9(conv9_up)\n",
    "        conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2) # Shortcut\n",
    "        conv10_2 = self.model10(conv10_up)\n",
    "        out_reg = self.model_out(conv10_2)\n",
    "\n",
    "        return out_reg\n",
    "\n",
    "##################\n",
    "# Loss functions #\n",
    "##################\n",
    "\n",
    "def berhu(prediction, target):\n",
    "    diff = prediction - target\n",
    "    threshold = 0.2*torch.max(torch.abs(prediction - target))\n",
    "    c = threshold.detach()\n",
    "    l2_part = torch.sum((diff**2 + c**2))/(2*c)\n",
    "    l1_part = torch.sum(torch.abs(diff))\n",
    "    return l1_part+l2_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing depthnet/data.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile depthnet/data.py\n",
    "###########\n",
    "# Dataset #\n",
    "###########\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import csv, numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from torchvision import transforms\n",
    "\n",
    "class DepthDataset(Dataset):\n",
    "    \"\"\"Class for reading and storing image and depth data together.\n",
    "    \"\"\"\n",
    "    def __init__(self, splitfile, dataDir, transform=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        images : list of (string, string)\n",
    "            list of (depth_map_path, rgb_path) filepaths to depth maps and their rgb images.\n",
    "        load_depth_map : function\n",
    "            the function for loading this particular kind of depth_map\n",
    "        load_rgb : function\n",
    "            the function for loading this particular kind of image.\n",
    "        \"\"\"\n",
    "        super(DepthDataset, self).__init__()\n",
    "        self.dataDir = dataDir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        with open(splitfile, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                self.data.append(line.strip().split(\",\"))\n",
    "#         print(self.data)\n",
    "    \n",
    "    def get_global_stats(self, outFile=None, writeFile=False):\n",
    "        \"\"\"Calculate mean and variance of each rgb channel.\n",
    "        \n",
    "        Optionally caches the result of this calculation in outfile so it doesn't need to be done each\n",
    "        time the dataset is loaded.\n",
    "        \"\"\"\n",
    "        S = np.zeros(3)\n",
    "        S_sq = np.zeros(3)\n",
    "        npixels = 0.\n",
    "        for depthFile, rgbFile in self.data:\n",
    "            rgbImg = Image.open(os.path.join(self.dataDir, rgbFile))\n",
    "            rgbImg = np.asarray(rgbImg, dtype=np.uint16)\n",
    "#             print(rgbImg[0:10, 0:10, :])\n",
    "            \n",
    "            npixels += rgbImg.shape[0]*rgbImg.shape[1]\n",
    "            for channel in range(rgbImg.shape[2]):\n",
    "                S[channel] += np.sum(rgbImg[:,:,channel])\n",
    "                S_sq[channel] += np.sum((rgbImg[:,:,channel])**2)\n",
    "        mean = S/npixels\n",
    "        var = S_sq/npixels - mean**2\n",
    "        \n",
    "        # Load full dataset (memory-intensive)\n",
    "#         full = []\n",
    "#         for depthFile, rgbFile in self.data:\n",
    "#             rgbImg = Image.open(os.path.join(self.dataDir, rgbFile))\n",
    "#             rgbImg = np.asarray(rgbImg, dtype=np.uint16)\n",
    "#             full.append(rgbImg)\n",
    "            \n",
    "#         a = np.array(full)\n",
    "#         mean_true = np.mean(a, axis=(0, 1, 2))\n",
    "#         var_true = np.var(a, axis=(0, 1, 2))\n",
    "#         print(\"actual mean and variance: {} {}\".format(mean_true, var_true))\n",
    "#         print(a.shape)\n",
    "        return mean, var\n",
    "                \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        depthFile, rgbFile = self.data[idx]\n",
    "        depthImg = Image.open(os.path.join(self.dataDir, depthFile))\n",
    "        rgbImg = Image.open(os.path.join(self.dataDir, rgbFile))\n",
    "        sample = {\"depth\": depthImg, \"rgb\": rgbImg}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "#############\n",
    "\n",
    "def load_data(trainFile, trainDir, devFile, devDir, trainTransform=None, valTransform=None):\n",
    "    \"\"\"Generates training and validation datasets from\n",
    "    text files and directories. Sets up datasets with transforms.\"\"\"\n",
    "    train = DepthDataset(trainFile, trainDir)\n",
    "    mean, var = train.get_global_stats()\n",
    "    train.transform = trainTransform\n",
    "    print(\"Loaded training dataset from {} with size {}.\".format(train_txt, len(train)))\n",
    "\n",
    "    val = DepthDataset(valFile, valDir, transform = valTransform)\n",
    "    print(\"Loaded val dataset from {} with size {}.\".format(dev_txt, len(dev)))\n",
    "    return train, val\n",
    "    \n",
    "##############\n",
    "# Transforms #\n",
    "##############\n",
    "# for data augmentation\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "\n",
    "        h, w = depth.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        depth = depth[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "        \n",
    "        rgb = rgb[top: top + new_h,\n",
    "                  left: left + new_w]\n",
    "\n",
    "        return {'depth': depth, 'rgb': rgb}\n",
    "\n",
    "class CenterCrop(object):\n",
    "    \"\"\"Center crop the image\n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "        h, w = depth.shape\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = h//2 - new_h//2\n",
    "        bottom = h//2 + new_h//2 + (1 if new_h % 2 else 0)\n",
    "        left = w//2 - new_w//2\n",
    "        right = w//2 + new_w//2 + (1 if new_w % 2 else 0)\n",
    "        \n",
    "        return {\"depth\": depth[top:bottom, left:right],\n",
    "                \"rgb\": rgb[top:bottom, left:right, :]}\n",
    "    \n",
    "class Crop_8(object):\n",
    "    \"\"\"Crop to a size where both dimensions are divisible by 8\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "        new_h, new_w = (depth.shape[0]//8)*8, (depth.shape[1]//8)*8\n",
    "        return {\"depth\": depth[:new_h, :new_w],\n",
    "                \"rgb\": rgb[:new_h, :new_w, :]}\n",
    "        \n",
    "class Crop_small(object):\n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "        h, w = depth.shape[:2]\n",
    "        x = 16\n",
    "        return {\"depth\": depth[h//2-x:h//2+x, w//2-x:w//2+x],\n",
    "                \"rgb\": rgb[h//2-x:h//2+x, w//2-x:w//2+x, :]}\n",
    "\n",
    "class ToFloat(object):\n",
    "    \"\"\"Also parses the depth info for sunrgbd.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        depth = sample['depth']\n",
    "        x = np.asarray(depth, dtype=np.uint16)\n",
    "        y = (x >> 3) | (x << 16-3)\n",
    "        z = y.astype(np.float32)/1000\n",
    "        z[z>8.] = 8. # Clip to maximum depth of 8m.\n",
    "        return {\"depth\": z,\n",
    "                \"rgb\": np.asarray(sample['rgb']).astype(np.float32)}\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        depth, rgb = sample['depth'], sample['rgb']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "#         depth = depth.transpose((2, 0, 1))\n",
    "        rgb = rgb.transpose((2, 0, 1))            \n",
    "        output = {}\n",
    "        if 'hist' in sample:\n",
    "            output['hist'] = torch.from_numpy(sample['hist']).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "#         print(output)\n",
    "        output.update({'depth': torch.from_numpy(depth).unsqueeze(0),\n",
    "                'rgb': torch.from_numpy(rgb)})\n",
    "        return output\n",
    "    \n",
    "class AddDepthHist(object):\n",
    "    \"\"\"Takes a depth map and computes a histogram of depths as well\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        kwargs - passthrough to np.histogram\n",
    "        \"\"\"\n",
    "        self.hist_kwargs = kwargs\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        depth = sample[\"depth\"]\n",
    "        hist, _ = np.histogram(depth, **self.hist_kwargs)\n",
    "#         print(hist)\n",
    "#         print(sample[\"depth\"])\n",
    "        return {\"depth\": sample[\"depth\"],\n",
    "                \"rgb\": sample[\"rgb\"],\n",
    "                \"hist\": hist}\n",
    "\n",
    "class NormalizeRGB(object):\n",
    "    def __init__(self, mean, var):\n",
    "        \"\"\"\n",
    "        mean - np.array of size 3 - the means of the three color channels over the whole (training) dataset\n",
    "        var - np.array of size 3 - the variances of the three color channels over the whole (training) dataset\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "    def __call__(self, sample):\n",
    "        sample[\"rgb\"] -= self.mean\n",
    "        sample[\"rgb\"] /= np.sqrt(self.var)\n",
    "#         print(sample[\"rgb\"][0:10, 0:10, 0])\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile depthnet/utils.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.cuda as cuda\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os.path\n",
    "# Helper functions\n",
    "\n",
    "#################\n",
    "# Checkpointing #\n",
    "#################\n",
    "def save_checkpoint(state, is_best, filename='/output/checkpoint.pth.tar', always_save=False):\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    if is_best or always_save:\n",
    "        print (\"=> Saving checkpoint to: {}\".format(filename))\n",
    "        torch.save(state, filename)  # save checkpoint\n",
    "    else:\n",
    "        print (\"=> Validation Accuracy did not improve\")\n",
    "\n",
    "##############\n",
    "# Validation #\n",
    "##############\n",
    "def validate(loss, model, val_loader):\n",
    "    \"\"\"Computes the validation error of the model on the validation set.\n",
    "    val_loader should be a DataLoader.\n",
    "    \n",
    "    Returns an ordinary number (i.e. not a tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    it = None\n",
    "    losses = []\n",
    "    for it, data in enumerate(val_loader):\n",
    "        depth = data[\"depth\"].float()\n",
    "        rgb = data[\"rgb\"].float()\n",
    "        if torch.cuda.is_available():\n",
    "            depth = depth.cuda()\n",
    "            rgb = rgb.cuda()\n",
    "        if \"hist\" in data:\n",
    "#             print(data)\n",
    "            hist = data[\"hist\"].float()\n",
    "            if torch.cuda.is_available():\n",
    "                hist = hist.cuda()\n",
    "#             print(hist)\n",
    "            output = model(rgb, hist)\n",
    "        else:\n",
    "            output = model(rgb)\n",
    "        losses.append(loss(output, depth).item())\n",
    "    nbatches = it+1\n",
    "    return sum(losses)/nbatches\n",
    "\n",
    "##################\n",
    "# Viewing Images #\n",
    "##################\n",
    "def save_images(*batches, outputDir, filename):\n",
    "    \"\"\"\n",
    "    Given a list of tensors of size (B, C, H, W) (batch, channels, height, width) torch.Tensor\n",
    "    Saves each entry of the batch as an rgb or grayscale image, depending on how many channels\n",
    "    the image has.\n",
    "    \"\"\"\n",
    "    I = None\n",
    "    trans = transforms.ToPILImage()\n",
    "    for batchnum, batch in enumerate(batches):\n",
    "        if batch.shape[1] == 3:\n",
    "            pass\n",
    "        elif batch.shape[1] == 1:\n",
    "            batch /= torch.max(batch) # normalize to lie in [0, 1]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported number of channels: {}\".format(batch.shape[1]))\n",
    "        batch = batch.type(torch.float32)\n",
    "        for img in range(batch.shape[0]):            \n",
    "            I = trans(batch[img,:,:,:].cpu().detach())\n",
    "            I.save(os.path.join(outputDir, filename + \"_{}_{}.png\".format(batchnum, img)))\n",
    "\n",
    "\n",
    "############\n",
    "# Plotting #\n",
    "############\n",
    "def save_train_val_loss_plots(trainlosses, vallosses, epoch):\n",
    "    # Train loss\n",
    "    fig = plt.figure()\n",
    "    plt.plot(trainlosses)\n",
    "    plt.title(\"Train loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"trainloss_epoch{}.png\".format(epoch))\n",
    "    # Train loss\n",
    "    fig = plt.figure()\n",
    "    plt.plot(trainlosses)\n",
    "    plt.title(\"Val loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Val loss{}.png\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training dataset from data/sunrgbd_nyu/train.txt with size 1159.\n",
      "Loaded dev dataset from data/sunrgbd_nyu/dev.txt with size 145.\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "def load_data(train_file, train_dir, dev_file, dev_dir)\n",
    "    train_txt = \"data/sunrgbd_nyu/train.txt\"\n",
    "    trainDir = \"data/sunrgbd_nyu\"\n",
    "    train = DepthDataset(train_txt, trainDir)\n",
    "    mean, var = train.get_global_stats()\n",
    "    train.transform = transforms.Compose([ToFloat(),\n",
    "    #                                       RandomCrop((400, 320)),\n",
    "                                          CenterCrop((320, 400)),\n",
    "                                          NormalizeRGB(mean, var),\n",
    "                                          ToTensor()\n",
    "                                          ])\n",
    "\n",
    "\n",
    "    #                      transform=transforms.Compose([ToFloat(), Crop_8(), ToFloat(), ToTensor()])\n",
    "    #                      transform=transforms.Compose([ToFloat(), Crop_small(), ToFloat(), ToTensor()])\n",
    "    # print(mean, var)\n",
    "\n",
    "    print(\"Loaded training dataset from {} with size {}.\".format(train_txt, len(train)))\n",
    "\n",
    "    dev_txt = \"data/sunrgbd_nyu/dev.txt\"\n",
    "    devDir = \"data/sunrgbd_nyu\"\n",
    "    dev = DepthDataset(dev_txt, devDir, \n",
    "                         transform = transforms.Compose([ToFloat(),\n",
    "                                                         CenterCrop((320, 400)), \n",
    "                                                         NormalizeRGB(mean, var),\n",
    "                                                         ToTensor(),])\n",
    "    #                      transform=transforms.Compose([ToFloat(), Crop_8(), ToTensor()])\n",
    "    #                      transform=transforms.Compose([ToFloat(), Crop_small(), ToTensor()])\n",
    "                        )\n",
    "    print(\"Loaded dev dataset from {} with size {}.\".format(dev_txt, len(dev)))\n",
    "    return train, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting depthnet/train_utils.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile depthnet/train_utils.py\n",
    "# Set up training.\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "from depthnet.model import DepthNet\n",
    "\n",
    "def setup_training(opt):\n",
    "    # Build model and loss\n",
    "    # Hyperparameters\n",
    "\n",
    "    model = DepthNet(opt.input_nc, opt.output_nc)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    # Checkpointing\n",
    "    if checkpointfile is not None:\n",
    "        if torch.cuda.is_available():\n",
    "            checkpoint = torch.load(checkpointfile)\n",
    "        else:\n",
    "            # Load GPU model on CPU\n",
    "            checkpoint = torch.load(checkpointfile,\n",
    "                                    map_location=lambda storage,\n",
    "                                    loc: storage)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_loss = checkpoint['best_loss']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
    "        trainlosses = checkpoint['trainlosses']\n",
    "        for i, trainloss in enumerate(trainlosses): # For tensorboardx\n",
    "            writer.add_scalar(\"data/trainloss\", trainloss, i)\n",
    "        vallosses = checkpoint['vallosses']\n",
    "        for i, valloss in enumerate(vallosses): # For tensorboardx\n",
    "            writer.add_scalar(\"data/valloss\", valloss, i)\n",
    "        global_it = len(trainlosses)\n",
    "        print(\"=> loaded checkpoint '{}' (trained for {} epoch(s)).\".format(checkpointfile, start_epoch))\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        global_it = 0 # Track global iterations\n",
    "        best_loss = torch.FloatTensor([float('inf')])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        trainlosses = []\n",
    "        vallosses = []\n",
    "        # Initialize weights:\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"conv\" in name and \"weight\" in name:\n",
    "    #             print(name)\n",
    "                nn.init.xavier_normal_(param)\n",
    "            if \"norm\" in name and \"weight\" in name:\n",
    "    #             print(name)\n",
    "                nn.init.constant_(param, 1)\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=0.1)\n",
    "    scheduler.last_epoch = start_epoch - 1\n",
    "\n",
    "    # Print summary of setup:\n",
    "    print(\"loaded checkpointfile: {}\".format(checkpointfile))\n",
    "    print(\"start_epoch: {}\".format(start_epoch))\n",
    "    print(\"global_it: {}\".format(global_it))\n",
    "    print(\"optimizer: {}\".format(optimizer))\n",
    "    print(\"batch_size: {}\".format(batch_size))\n",
    "    print(\"num_epochs: {}\".format(num_epochs))\n",
    "    print(\"learning rate (initial): {}\".format(learning_rate))\n",
    "    print(\"scheduler: {}\".format(scheduler.state_dict()))\n",
    "    \n",
    "    out = {\"model\": model,\n",
    "           \"start_epoch\": start_epoch,\n",
    "           \"num_epochs\": num_epochs,\n",
    "           \"global_it\": global_it,\n",
    "           \"scheduler\": scheduler\n",
    "          }\n",
    "    return out\n",
    "\n",
    "####################\n",
    "# Run the training #\n",
    "####################\n",
    "def train(model, loss, start_epoch, num_epochs, global_it, scheduler, trainLoader, valLoader=None, test_run=False, writer=None):\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        print(\"epoch: {}\".format(epoch))\n",
    "        data = None\n",
    "        output = None\n",
    "        for it, data in enumerate(trainLoader):\n",
    "            depth = data[\"depth\"].float()\n",
    "            rgb = data[\"rgb\"].float()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                depth = depth.cuda()\n",
    "                rgb = rgb.cuda()\n",
    "            # New batch\n",
    "            scheduler.optimizer.zero_grad()\n",
    "            output = model(rgb)\n",
    "            trainloss = loss(output, depth)\n",
    "            trainloss.backward()\n",
    "            scheduler.optimizer.step()\n",
    "            global_it += 1\n",
    "\n",
    "            if not (it % 10):\n",
    "                print(\"\\titeration: {}\\ttrain loss: {}\".format(it, trainloss.item()))\n",
    "            trainlosses.append(trainloss.item())\n",
    "            writer.add_scalar(\"data/trainloss\", trainloss.item(), global_it)\n",
    "\n",
    "            if test_run: # Stop after 5 batches\n",
    "                if not ((it + 1) % 5):\n",
    "                    break\n",
    "        # Checkpointing\n",
    "        if valLoader is not None:\n",
    "            valloss = validate(loss, model, valLoader)\n",
    "            print(\"End epoch {}\\tval loss: {}\".format(epoch, valloss))\n",
    "            vallosses.append(valloss)\n",
    "            writer.add_scalar(\"data/valloss\", valloss, epoch)\n",
    "\n",
    "        # Save the last batch output of every epoch\n",
    "        rgb_input = vutils.make_grid(data[\"rgb\"], nrow=batch_size, normalize=True, scale_each=True)\n",
    "        writer.add_image('image/rgb_input', rgb_input, epoch)\n",
    "\n",
    "        depth_truth = vutils.make_grid(data[\"depth\"], nrow=batch_size, normalize=True, scale_each=True)\n",
    "        writer.add_image('image/depth_truth', depth_truth, epoch)\n",
    "\n",
    "        depth_output = vutils.make_grid(output, nrow=batch_size, normalize=True, scale_each=True)\n",
    "        writer.add_image('image/depth_output', depth_output, epoch)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), global_it)\n",
    "    #     save_images(data[\"rgb\"], data[\"depth\"], output, outputDir=\"images\", filename=\"epoch_{}\".format(epoch))\n",
    "\n",
    "        is_best = bool(trainloss.data.cpu().numpy() < best_loss.numpy())\n",
    "        # Get greater Tensor to keep track best acc\n",
    "        best_loss = torch.FloatTensor(min(trainloss.data.cpu().numpy(), best_loss.numpy()))\n",
    "        # Save checkpoint\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_loss': best_loss,\n",
    "            'optim_state_dict': optimizer.state_dict(),\n",
    "            'trainlosses': trainlosses,\n",
    "            'vallosses': vallosses\n",
    "        }, is_best, filename=\"checkpoints/checkpoint_epoch_{}.pth.tar\".format(epoch), always_save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n",
      "\titeration: 0\ttrain loss: 0.46216171979904175\n",
      "\titeration: 10\ttrain loss: 0.2399614304304123\n",
      "\titeration: 20\ttrain loss: 0.5442972779273987\n",
      "\titeration: 30\ttrain loss: 0.288849800825119\n",
      "\titeration: 40\ttrain loss: 0.4346057176589966\n",
      "\titeration: 50\ttrain loss: 0.30571889877319336\n",
      "\titeration: 60\ttrain loss: 0.36826014518737793\n",
      "\titeration: 70\ttrain loss: 0.3332650363445282\n",
      "\titeration: 80\ttrain loss: 0.2840162515640259\n",
      "\titeration: 90\ttrain loss: 0.4139283299446106\n",
      "\titeration: 100\ttrain loss: 0.32223719358444214\n",
      "\titeration: 110\ttrain loss: 0.5264000296592712\n",
      "End epoch 50\tval loss: 1.5325142062943558\n",
      "=> Saving checkpoint to: checkpoints/checkpoint_epoch_50.pth.tar\n",
      "epoch: 51\n",
      "\titeration: 0\ttrain loss: 0.4966995120048523\n",
      "\titeration: 10\ttrain loss: 0.4325902760028839\n",
      "\titeration: 20\ttrain loss: 0.3255394399166107\n",
      "\titeration: 30\ttrain loss: 0.8746808767318726\n",
      "\titeration: 40\ttrain loss: 0.554697573184967\n",
      "\titeration: 50\ttrain loss: 0.40921124815940857\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Run the training #\n",
    "####################\n",
    "def train(model, scheduler, start_epoch, num_epochs, writer, trainLoader, valLoader=None, test_run=False):\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        print(\"epoch: {}\".format(epoch))\n",
    "        data = None\n",
    "        output = None\n",
    "        for it, data in enumerate(trainLoader):\n",
    "            depth = data[\"depth\"].float()\n",
    "            rgb = data[\"rgb\"].float()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                depth = depth.cuda()\n",
    "                rgb = rgb.cuda()\n",
    "            # New batch\n",
    "            scheduler.optimizer.zero_grad()\n",
    "            output = model(rgb)\n",
    "            trainloss = loss(output, depth)\n",
    "            trainloss.backward()\n",
    "            scheduler.optimizer.step()\n",
    "            global_it += 1\n",
    "\n",
    "            if not (it % 10):\n",
    "                print(\"\\titeration: {}\\ttrain loss: {}\".format(it, trainloss.item()))\n",
    "            trainlosses.append(trainloss.item())\n",
    "            writer.add_scalar(\"data/trainloss\", trainloss.item(), global_it)\n",
    "\n",
    "            if test_run: # Stop after 5 batches\n",
    "                if not ((it + 1) % 5):\n",
    "                    break\n",
    "        # Checkpointing\n",
    "        if valLoader is not None:\n",
    "            valloss = validate(loss, model, valLoader)\n",
    "            print(\"End epoch {}\\tval loss: {}\".format(epoch, valloss))\n",
    "            vallosses.append(valloss)\n",
    "            writer.add_scalar(\"data/valloss\", valloss, epoch)\n",
    "\n",
    "        # Save the last batch output of every epoch\n",
    "        rgb_input = vutils.make_grid(data[\"rgb\"], nrow=batch_size, normalize=True, scale_each=True)\n",
    "        writer.add_image('image/rgb_input', rgb_input, epoch)\n",
    "\n",
    "        depth_truth = vutils.make_grid(data[\"depth\"], nrow=batch_size, normalize=True, scale_each=True)\n",
    "        writer.add_image('image/depth_truth', depth_truth, epoch)\n",
    "\n",
    "        depth_output = vutils.make_grid(output, nrow=batch_size, normalize=True, scale_each=True)\n",
    "        writer.add_image('image/depth_output', depth_output, epoch)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), global_it)\n",
    "    #     save_images(data[\"rgb\"], data[\"depth\"], output, outputDir=\"images\", filename=\"epoch_{}\".format(epoch))\n",
    "\n",
    "        is_best = bool(trainloss.data.cpu().numpy() < best_loss.numpy())\n",
    "        # Get greater Tensor to keep track best acc\n",
    "        best_loss = torch.FloatTensor(min(trainloss.data.cpu().numpy(), best_loss.numpy()))\n",
    "        # Save checkpoint\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_loss': best_loss,\n",
    "            'optim_state_dict': optimizer.state_dict(),\n",
    "            'trainlosses': trainlosses,\n",
    "            'vallosses': vallosses\n",
    "        }, is_best, filename=\"checkpoints/checkpoint_epoch_{}.pth.tar\".format(epoch), always_save=True)\n",
    "\n",
    "# Close tensorboardX    \n",
    "# writer.export_scalars_to_json(\"./all_scalars.json\") # for other processing\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing depthnet/options.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile depthnet/options.py\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "opt = ArgumentParser(description=\"Load command line options for depthnet.\")\n",
    "# Learning rates:\n",
    "opt.add_argument(\"--lr\", help=\"The initial learning rate of the model.\",\n",
    "                 type=float, default=1e-5)\n",
    "opt.add_argument(\"--weight-decay\", help=\"The strength of the L2 regularization on the weights.\",\n",
    "                 type=float, default=1e-8)\n",
    "\n",
    "# Training hyperparameters:\n",
    "# For reference: scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30], gamma=0.1)\n",
    "opt.add_argument(\"--num-epochs\", help=\"The number of epochs to train the model.\",\n",
    "                 type=int, default=50)\n",
    "opt.add_argument(\"--milestones\", help=\"Learning rate milestone epochs.\", nargs=\"*\",\n",
    "                 type=int, default=[25])\n",
    "opt.add_argument(\"--gamma\", help=\"Gamma of multistepLR lr decay.\",\n",
    "                 type=float, default=0.1)\n",
    "\n",
    "# Data Loading\n",
    "opt.add_argument(\"trainFile\", help=\"The location of the text file with the (depth, rgb) pairs.\",\n",
    "                 type=str)\n",
    "opt.add_argument(\"trainDir\", help=\"The folder containing the rgb-d training images.\",\n",
    "                 type=str)\n",
    "opt.add_argument(\"--valFile\", \n",
    "                 help=\"The location of the text file with the (depth, rgb) pairs for the validation dataset.\",\n",
    "                 type=str)\n",
    "opt.add_argument(\"--valDir\",\n",
    "                 help=\"The location of the text file with the (depth, rgb) pairs for the validation dataset.\",\n",
    "                 type=str)\n",
    "opt.add_argument(\"--batch-size\", help=\"The batch size for training.\",\n",
    "                 type=int, default=10)\n",
    "opt.add_argument(\"--val-batch-size\", help=\"The batch size of the validation set.\",\n",
    "                 type=int, default=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing depthnet/train.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile depthnet/train.py\n",
    "# Load training options from file\n",
    "from depthnet.options import opt\n",
    "# Tensorboardx\n",
    "writer = SummaryWriter()\n",
    "# data_trainloss = \"data/trainloss\"\n",
    "# data_valloss = \"data/valloss\"\n",
    "# Image = \"Image\"\n",
    "\n",
    "# Load data\n",
    "train, val = load_data(trainFile = opt.trainFile,\n",
    "                       trainDir = opt.trainDir,\n",
    "                       valFile = opt.valFile,\n",
    "                       valDir = opt.valDir)\n",
    "\n",
    "trainLoader = DataLoader(train, batch_size=opt.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valLoader = DataLoader(val, batch_size=opt.val_batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Load model, loss, and scheduler\n",
    "loss = None\n",
    "if opt.loss == \"berhu\":\n",
    "    from depthnet.model import berhu\n",
    "    loss = berhu\n",
    "elif opt.loss == \"l2\":\n",
    "    loss = MSELoss()\n",
    "    if torch.cuda.is_available():\n",
    "        loss.cuda()\n",
    "elif opt.loss == \"l1\":\n",
    "    loss = L1Loss()\n",
    "    if torch.cuda.is_available():\n",
    "        loss.cuda()\n",
    "\n",
    "# Run Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training loss\n",
    "\n",
    "trainlosses = checkpoint['vallosses']\n",
    "plt.semilogy(trainlosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "print(type(rgb))\n",
    "imshow(rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# Load data\n",
    "a = torch.ones(1, requires_grad=True)\n",
    "b = torch.ones(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b\n",
    "c.register_hook(print)\n",
    "s = a**2 + b**2\n",
    "s.register_hook(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = torch.sum(c)\n",
    "e = c.detach()\n",
    "f = torch.sum(s)\n",
    "g = f/e\n",
    "g.backward()\n",
    "# s.backward()\n",
    "# f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
