{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T01:08:54.354993Z",
     "start_time": "2019-09-26T01:08:50.965674Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.signal as signal\n",
    "import torch\n",
    "\n",
    "# Models\n",
    "from DenseDepthModel import DenseDepth\n",
    "from DORN import DORN\n",
    "from MiDaSModel import get_midas, midas_predict\n",
    "from capture_utils import loadmat_h5py, z_to_r, r_to_z, rescale_bins, normals_from_depth, fc_kinect, fc_spad, \\\n",
    "                          get_closer_to_mod, load_spad, preprocess_spad, load_and_crop_kinect, get_hist_med, \\\n",
    "                          depth_imwrite, savefig_no_whitespace\n",
    "from models.data.data_utils.sid_utils import SID\n",
    "from models.loss import get_depth_metrics\n",
    "from remove_dc_from_spad import remove_dc_from_spad_edge\n",
    "from weighted_histogram_matching import image_histogram_match\n",
    "# from spad_utils import rescale_bins\n",
    "\n",
    "from camera_utils import extract_camera_params, project_depth, undistort_img\n",
    "\n",
    "from models.core.checkpoint import safe_makedir\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T01:09:35.977379Z",
     "start_time": "2019-09-26T01:08:54.359419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291\n",
      "11.0016\n",
      "using device: cuda (CUDA_VISIBLE_DEVICES = 0)\n",
      "Loaded state dict file from models/torch_params_nyuv2_BGR.pth.tar\n",
      "WARNING:tensorflow:From /home/markn1/anaconda3/envs/depth-net/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "Existing model loaded.\n",
      "\n",
      "Model created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markn1/anaconda3/envs/depth-net/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data\"\n",
    "calibration_file = os.path.join(data_dir, \"calibration\", \"camera_params.mat\")\n",
    "scene = \"8_31_outdoor3\"\n",
    "# Relative shift of projected depth to rgb (found empirically)\n",
    "\n",
    "bin_width_ps = 32\n",
    "bin_width_m = bin_width_ps*3e8/(2*1e12)\n",
    "min_depth_bin = np.floor(0.4/bin_width_m).astype('int')\n",
    "max_depth_bin = np.floor(11./bin_width_m).astype('int')\n",
    "min_depth = min_depth_bin * bin_width_m\n",
    "max_depth = (max_depth_bin + 1) * bin_width_m\n",
    "sid_obj = SID(sid_bins=140, alpha=min_depth, beta=max_depth, offset=0)\n",
    "ambient_max_depth_bin = 100\n",
    "\n",
    "print(max_depth_bin)\n",
    "print(max_depth)\n",
    "\n",
    "cuda_device = \"0\"                       # The gpu index to run on. Should be a string\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device: {} (CUDA_VISIBLE_DEVICES = {})\".format(device,\n",
    "                                                            os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "offset = (0,0)\n",
    "\n",
    "midas_model = get_midas(model_path=\"MiDaS/model.pt\", device=device)\n",
    "dorn_model = DORN()\n",
    "dorn_model.eval()\n",
    "densedepth_model = DenseDepth()\n",
    "fc_kinect, fc_spad, pc_kinect, pc_spad, rdc_kinect, rdc_spad, tdc_kinect, tdc_spad, \\\n",
    "    RotationOfSpad, TranslationOfSpad = extract_camera_params(calibration_file)\n",
    "# print(fc_kinect)\n",
    "# print(fc_spad)\n",
    "RotationOfKinect = RotationOfSpad.T\n",
    "TranslationOfKinect = -TranslationOfSpad.dot(RotationOfSpad.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-26T01:08:51.904Z"
    }
   },
   "outputs": [],
   "source": [
    "# MiDaS\n",
    "print(\"Running {}...\".format(scene))\n",
    "output_dir = os.path.join(\"figures\", \"midas\")\n",
    "rootdir = os.path.join(data_dir, scene)\n",
    "scenedir = os.path.join(output_dir, scene)\n",
    "\n",
    "safe_makedir(os.path.join(scenedir))\n",
    "# Load all the SPAD and kinect data\n",
    "spad = load_spad(os.path.join(rootdir, \"spad_20m\", \"data_accum.mat\"))\n",
    "# print(spad.shape)\n",
    "spad_relevant = spad[..., min_depth_bin:max_depth_bin]\n",
    "spad_single_relevant = np.sum(spad_relevant, axis=(0,1))\n",
    "ambient_estimate = np.mean(spad_single_relevant[:ambient_max_depth_bin])\n",
    "\n",
    "# Get ground truth depth\n",
    "gt_idx = np.argmax(spad_relevant, axis=2)\n",
    "gt_r = signal.medfilt(np.fliplr(np.flipud(((gt_idx + min_depth_bin)* bin_width_m).T)), kernel_size=5)\n",
    "mask = (gt_r >= min_depth).astype('float').squeeze()\n",
    "gt_z = r_to_z(gt_r, fc_spad)\n",
    "gt_z = undistort_img(gt_z, fc_spad, pc_spad, rdc_spad, tdc_spad)\n",
    "mask = np.round(undistort_img(mask, fc_spad, pc_spad, rdc_spad, tdc_spad))\n",
    "# Nearest neighbor upsampling to reduce holes in output\n",
    "scale_factor = 2\n",
    "gt_z_up = cv2.resize(gt_z, dsize=(scale_factor*gt_z.shape[0], scale_factor*gt_z.shape[1]),\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "mask_up = cv2.resize(mask, dsize=(scale_factor*mask.shape[0], scale_factor*mask.shape[1]),\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Get RGB and intensity\n",
    "rgb, rgb_cropped, intensity, crop = load_and_crop_kinect(rootdir, kinect_file=\"kinect_finish.mat\")\n",
    "\n",
    "\n",
    "# Project GT depth and mask to RGB image coordinates and crop it.\n",
    "gt_z_proj, mask_proj = project_depth(gt_z_up, mask_up, (rgb.shape[0], rgb.shape[1]),\n",
    "                                     fc_spad*scale_factor, fc_kinect, pc_spad*scale_factor, pc_kinect,\n",
    "                                     RotationOfKinect, TranslationOfKinect/1e3)\n",
    "gt_z_proj_crop = gt_z_proj[crop[0]+offset[0]:crop[1]+offset[0],\n",
    "                           crop[2]+offset[1]:crop[3]+offset[1]]\n",
    "gt_z_proj_crop = signal.medfilt(gt_z_proj_crop, kernel_size=5)\n",
    "# mask_proj_crop = mask_proj[crop[0]+offset[0]:crop[1]+offset[0],\n",
    "#                            crop[2]+offset[1]:crop[3]+offset[1]]\n",
    "mask_proj_crop = (gt_z_proj_crop >= min_depth).astype('float').squeeze()\n",
    "\n",
    "# Process SPAD\n",
    "spad_sid = preprocess_spad(spad_single_relevant, ambient_estimate, min_depth, max_depth, sid_obj)\n",
    "\n",
    "# Initialize with CNN\n",
    "z_init = midas_predict(midas_model, rgb_cropped/255., depth_range=(min_depth, max_depth), device=device)\n",
    "r_init = z_to_r(z_init, fc_kinect)\n",
    "\n",
    "# Histogram Match\n",
    "weights = intensity\n",
    "r_pred, t = image_histogram_match(r_init, spad_sid, weights, sid_obj)\n",
    "z_pred = r_to_z(r_pred, fc_kinect)\n",
    "\n",
    "# Mean Match\n",
    "med_bin = get_hist_med(spad_sid)\n",
    "hist_med = sid_obj.sid_bin_values[med_bin.astype('int')]\n",
    "r_med_scaled = np.clip(r_init * hist_med/np.median(r_init), a_min=min_depth, a_max=max_depth)\n",
    "z_med_scaled = r_to_z(r_med_scaled, fc_kinect)\n",
    "\n",
    "# Find min and max depth across r and z separately\n",
    "min_r = min(np.min(a) for a in [gt_r, r_init, r_pred, r_med_scaled])\n",
    "max_r = max(np.max(a) for a in [gt_r, r_init, r_pred, r_med_scaled])\n",
    "min_z = min(np.min(a) for a in [gt_z, z_init, z_pred, z_med_scaled, gt_z_proj, gt_z_proj_crop])\n",
    "max_z = max(np.max(a) for a in [gt_z, z_init, z_pred, z_med_scaled, gt_z_proj, gt_z_proj_crop])\n",
    "mins_and_maxes = {\n",
    "    \"min_r\": min_r,\n",
    "    \"max_r\": max_r,\n",
    "    \"min_z\": min_z,\n",
    "    \"max_z\": max_z\n",
    "}\n",
    "\n",
    "# Save stuff\n",
    "np.save(os.path.join(scenedir, \"mins_and_maxes.npy\"), mins_and_maxes)\n",
    "\n",
    "# Save to figures\n",
    "print(\"Saving figures...\")\n",
    "# spad_single_relevant w/ ambient estimate\n",
    "plt.figure()\n",
    "plt.bar(range(len(spad_single_relevant)), spad_single_relevant, log=True)\n",
    "plt.title(\"spad_single_relevant\".format(scene))\n",
    "plt.axhline(y=ambient_estimate, color='r', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(scenedir, \"spad_single_relevant.pdf\"))\n",
    "# gt_r and gt_z and gt_z_proj and gt_z_proj_crop and masks\n",
    "depth_imwrite(gt_r, min_r, max_r, os.path.join(scenedir, \"gt_r\"))\n",
    "depth_imwrite(gt_z, min_z, max_z, os.path.join(scenedir, \"gt_z\"))\n",
    "depth_imwrite(gt_z_proj, min_z, max_z, os.path.join(scenedir, \"gt_z_proj\"))\n",
    "depth_imwrite(gt_z_proj_crop, min_z, max_z, os.path.join(scenedir, \"gt_z_proj_crop\"))\n",
    "depth_imwrite(mask, 0., 1., os.path.join(scenedir, \"mask\"))\n",
    "depth_imwrite(mask_proj, 0., 1., os.path.join(scenedir, \"mask_proj\"))\n",
    "depth_imwrite(mask_proj_crop, 0., 1., os.path.join(scenedir, \"mask_proj_crop\"))\n",
    "depth_imwrite(intensity, 0., 1., os.path.join(scenedir, \"intensity\"))\n",
    "np.save(os.path.join(scenedir, \"crop.npy\"), crop)\n",
    "# spad_sid after preprocessing\n",
    "plt.figure()\n",
    "plt.bar(range(len(spad_sid)), spad_sid, log=True)\n",
    "plt.title(\"spad_sid\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(scenedir, \"spad_sid.pdf\"))\n",
    "# rgb, rgb_cropped, intensity\n",
    "cv2.imwrite(os.path.join(scenedir, \"rgb.png\"), cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(os.path.join(scenedir, \"rgb_cropped.png\"), cv2.cvtColor(rgb_cropped, cv2.COLOR_RGB2BGR))\n",
    "# r_init, z_init, diff_maps\n",
    "depth_imwrite(r_init, min_r, max_r, os.path.join(scenedir, \"r_init\"))\n",
    "depth_imwrite(z_init, min_z, max_z, os.path.join(scenedir, \"z_init\"))\n",
    "# r_pred, z_pred, diff_maps\n",
    "depth_imwrite(r_pred, min_r, max_r, os.path.join(scenedir, \"r_pred\"))\n",
    "depth_imwrite(z_pred, min_z, max_z, os.path.join(scenedir, \"z_pred\"))\n",
    "# r_med_scaled, z_med_scaled, diff_maps\n",
    "depth_imwrite(r_med_scaled, min_r, max_r, os.path.join(scenedir, \"r_med_scaled\"))\n",
    "depth_imwrite(z_med_scaled, min_z, max_z, os.path.join(scenedir, \"z_med_scaled\"))\n",
    "plt.close('all')\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Computing error metrics...\")\n",
    "# z_init\n",
    "# z_init_resized = cv2.resize(z_init, gt_z.shape)\n",
    "init_metrics = get_depth_metrics(torch.from_numpy(z_init).float(),\n",
    "                                 torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                 torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"init_metrics.npy\"), init_metrics)\n",
    "# z_pred\n",
    "# z_pred_resized = cv2.resize(z_pred, gt_z.shape)\n",
    "pred_metrics = get_depth_metrics(torch.from_numpy(z_pred).float(),\n",
    "                                 torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                 torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"pred_metrics.npy\"), pred_metrics)\n",
    "\n",
    "# z_med_scaled\n",
    "# z_med_scaled_resized = cv2.resize(z_med_scaled, gt_z.shape)\n",
    "med_scaled_metrics = get_depth_metrics(torch.from_numpy(z_med_scaled).float(),\n",
    "                                       torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                       torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"med_scaled_metrics.npy\"), med_scaled_metrics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-26T01:08:52.560Z"
    }
   },
   "outputs": [],
   "source": [
    "# MiDaS figures\n",
    "plt.figure()\n",
    "plt.imshow(rgb_cropped)\n",
    "plt.figure()\n",
    "plt.imshow(gt_z_proj_crop)\n",
    "plt.figure()\n",
    "plt.imshow(z_init)\n",
    "plt.figure()\n",
    "plt.imshow(z_pred)\n",
    "plt.figure()\n",
    "plt.imshow(z_med_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-26T01:08:53.064Z"
    }
   },
   "outputs": [],
   "source": [
    "# DenseDepth\n",
    "print(\"Running {}...\".format(scene))\n",
    "output_dir = os.path.join(\"figures\", \"densedepth\")\n",
    "rootdir = os.path.join(data_dir, scene)\n",
    "scenedir = os.path.join(output_dir, scene)\n",
    "\n",
    "safe_makedir(os.path.join(scenedir))\n",
    "# Load all the SPAD and kinect data\n",
    "spad = load_spad(os.path.join(rootdir, \"spad_20m\", \"data_accum.mat\"))\n",
    "# print(spad.shape)\n",
    "spad_relevant = spad[..., min_depth_bin:max_depth_bin]\n",
    "spad_single_relevant = np.sum(spad_relevant, axis=(0,1))\n",
    "ambient_estimate = np.mean(spad_single_relevant[:ambient_max_depth_bin])\n",
    "\n",
    "# Get ground truth depth\n",
    "gt_idx = np.argmax(spad_relevant, axis=2)\n",
    "gt_r = signal.medfilt(np.fliplr(np.flipud(((gt_idx + min_depth_bin)* bin_width_m).T)), kernel_size=5)\n",
    "mask = (gt_r >= min_depth).astype('float').squeeze()\n",
    "gt_z = r_to_z(gt_r, fc_spad)\n",
    "gt_z = undistort_img(gt_z, fc_spad, pc_spad, rdc_spad, tdc_spad)\n",
    "mask = np.round(undistort_img(mask, fc_spad, pc_spad, rdc_spad, tdc_spad))\n",
    "# Nearest neighbor upsampling to reduce holes in output\n",
    "scale_factor = 2\n",
    "gt_z_up = cv2.resize(gt_z, dsize=(scale_factor*gt_z.shape[0], scale_factor*gt_z.shape[1]),\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "mask_up = cv2.resize(mask, dsize=(scale_factor*mask.shape[0], scale_factor*mask.shape[1]),\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Get RGB and intensity\n",
    "rgb, rgb_cropped, intensity, crop = load_and_crop_kinect(rootdir, kinect_file=\"kinect_finish.mat\")\n",
    "\n",
    "\n",
    "# Project GT depth and mask to RGB image coordinates and crop it.\n",
    "gt_z_proj, mask_proj = project_depth(gt_z_up, mask_up, (rgb.shape[0], rgb.shape[1]),\n",
    "                                     fc_spad*scale_factor, fc_kinect, pc_spad*scale_factor, pc_kinect,\n",
    "                                     RotationOfKinect, TranslationOfKinect/1e3)\n",
    "gt_z_proj_crop = gt_z_proj[crop[0]+offset[0]:crop[1]+offset[0],\n",
    "                           crop[2]+offset[1]:crop[3]+offset[1]]\n",
    "gt_z_proj_crop = signal.medfilt(gt_z_proj_crop, kernel_size=5)\n",
    "# mask_proj_crop = mask_proj[crop[0]+offset[0]:crop[1]+offset[0],\n",
    "#                            crop[2]+offset[1]:crop[3]+offset[1]]\n",
    "mask_proj_crop = (gt_z_proj_crop >= min_depth).astype('float').squeeze()\n",
    "\n",
    "# Process SPAD\n",
    "spad_sid = preprocess_spad(spad_single_relevant, ambient_estimate, min_depth, max_depth, sid_obj)\n",
    "\n",
    "# Initialize with CNN\n",
    "z_init = densedepth_model.predict(rgb_cropped).squeeze()\n",
    "r_init = z_to_r(z_init, fc_kinect)\n",
    "\n",
    "# Histogram Match\n",
    "weights = intensity\n",
    "r_pred, t = image_histogram_match(r_init, spad_sid, weights, sid_obj)\n",
    "z_pred = r_to_z(r_pred, fc_kinect)\n",
    "\n",
    "# Mean Match\n",
    "med_bin = get_hist_med(spad_sid)\n",
    "hist_med = sid_obj.sid_bin_values[med_bin.astype('int')]\n",
    "r_med_scaled = np.clip(r_init * hist_med/np.median(r_init), a_min=min_depth, a_max=max_depth)\n",
    "z_med_scaled = r_to_z(r_med_scaled, fc_kinect)\n",
    "\n",
    "# Find min and max depth across r and z separately\n",
    "min_r = min(np.min(a) for a in [gt_r, r_init, r_pred, r_med_scaled])\n",
    "max_r = max(np.max(a) for a in [gt_r, r_init, r_pred, r_med_scaled])\n",
    "min_z = min(np.min(a) for a in [gt_z, z_init, z_pred, z_med_scaled, gt_z_proj, gt_z_proj_crop])\n",
    "max_z = max(np.max(a) for a in [gt_z, z_init, z_pred, z_med_scaled, gt_z_proj, gt_z_proj_crop])\n",
    "mins_and_maxes = {\n",
    "    \"min_r\": min_r,\n",
    "    \"max_r\": max_r,\n",
    "    \"min_z\": min_z,\n",
    "    \"max_z\": max_z\n",
    "}\n",
    "\n",
    "# Save stuff\n",
    "np.save(os.path.join(scenedir, \"mins_and_maxes.npy\"), mins_and_maxes)\n",
    "\n",
    "# Save to figures\n",
    "print(\"Saving figures...\")\n",
    "# spad_single_relevant w/ ambient estimate\n",
    "plt.figure()\n",
    "plt.bar(range(len(spad_single_relevant)), spad_single_relevant, log=True)\n",
    "plt.title(\"spad_single_relevant\".format(scene))\n",
    "plt.axhline(y=ambient_estimate, color='r', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(scenedir, \"spad_single_relevant.pdf\"))\n",
    "# gt_r and gt_z and gt_z_proj and gt_z_proj_crop and masks\n",
    "depth_imwrite(gt_r, min_r, max_r, os.path.join(scenedir, \"gt_r\"))\n",
    "depth_imwrite(gt_z, min_z, max_z, os.path.join(scenedir, \"gt_z\"))\n",
    "depth_imwrite(gt_z_proj, min_z, max_z, os.path.join(scenedir, \"gt_z_proj\"))\n",
    "depth_imwrite(gt_z_proj_crop, min_z, max_z, os.path.join(scenedir, \"gt_z_proj_crop\"))\n",
    "depth_imwrite(mask, 0., 1., os.path.join(scenedir, \"mask\"))\n",
    "depth_imwrite(mask_proj, 0., 1., os.path.join(scenedir, \"mask_proj\"))\n",
    "depth_imwrite(mask_proj_crop, 0., 1., os.path.join(scenedir, \"mask_proj_crop\"))\n",
    "depth_imwrite(intensity, 0., 1., os.path.join(scenedir, \"intensity\"))\n",
    "np.save(os.path.join(scenedir, \"crop.npy\"), crop)\n",
    "# spad_sid after preprocessing\n",
    "plt.figure()\n",
    "plt.bar(range(len(spad_sid)), spad_sid, log=True)\n",
    "plt.title(\"spad_sid\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(scenedir, \"spad_sid.pdf\"))\n",
    "# rgb, rgb_cropped, intensity\n",
    "cv2.imwrite(os.path.join(scenedir, \"rgb.png\"), cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(os.path.join(scenedir, \"rgb_cropped.png\"), cv2.cvtColor(rgb_cropped, cv2.COLOR_RGB2BGR))\n",
    "# r_init, z_init, diff_maps\n",
    "depth_imwrite(r_init, min_r, max_r, os.path.join(scenedir, \"r_init\"))\n",
    "depth_imwrite(z_init, min_z, max_z, os.path.join(scenedir, \"z_init\"))\n",
    "# r_pred, z_pred, diff_maps\n",
    "depth_imwrite(r_pred, min_r, max_r, os.path.join(scenedir, \"r_pred\"))\n",
    "depth_imwrite(z_pred, min_z, max_z, os.path.join(scenedir, \"z_pred\"))\n",
    "# r_med_scaled, z_med_scaled, diff_maps\n",
    "depth_imwrite(r_med_scaled, min_r, max_r, os.path.join(scenedir, \"r_med_scaled\"))\n",
    "depth_imwrite(z_med_scaled, min_z, max_z, os.path.join(scenedir, \"z_med_scaled\"))\n",
    "plt.close('all')\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Computing error metrics...\")\n",
    "# z_init\n",
    "# z_init_resized = cv2.resize(z_init, gt_z.shape)\n",
    "init_metrics = get_depth_metrics(torch.from_numpy(z_init).float(),\n",
    "                                 torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                 torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"init_metrics.npy\"), init_metrics)\n",
    "# z_pred\n",
    "# z_pred_resized = cv2.resize(z_pred, gt_z.shape)\n",
    "pred_metrics = get_depth_metrics(torch.from_numpy(z_pred).float(),\n",
    "                                 torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                 torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"pred_metrics.npy\"), pred_metrics)\n",
    "\n",
    "# z_med_scaled\n",
    "# z_med_scaled_resized = cv2.resize(z_med_scaled, gt_z.shape)\n",
    "med_scaled_metrics = get_depth_metrics(torch.from_numpy(z_med_scaled).float(),\n",
    "                                       torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                       torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"med_scaled_metrics.npy\"), med_scaled_metrics)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-26T01:08:53.526Z"
    }
   },
   "outputs": [],
   "source": [
    "# DenseDepth figures\n",
    "plt.figure()\n",
    "plt.imshow(rgb_cropped)\n",
    "plt.figure()\n",
    "plt.imshow(gt_z_proj_crop)\n",
    "plt.figure()\n",
    "plt.imshow(z_init)\n",
    "plt.figure()\n",
    "plt.imshow(z_pred)\n",
    "plt.figure()\n",
    "plt.imshow(z_med_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-26T01:08:54.658Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dorn_predict(model, rgb):\n",
    "    \"\"\"\n",
    "    :param rgb: RGB image in [0, 255]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rgb_torch = torch.from_numpy(rgb.transpose(2, 0, 1).copy()).float().unsqueeze(0)\n",
    "    # print(rgb_torch.shape)\n",
    "    bgr = model.preprocess(rgb_torch)\n",
    "    # print(bgr.shape)\n",
    "    z_init_torch = model.predict(bgr, resize_output=(rgb_torch.shape[2], rgb_torch.shape[3]))\n",
    "    z_init = z_init_torch.cpu().numpy().squeeze()\n",
    "    return z_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-26T01:08:54.991Z"
    }
   },
   "outputs": [],
   "source": [
    "# DORN\n",
    "print(\"Running {}...\".format(scene))\n",
    "output_dir = os.path.join(\"figures\", \"dorn\")\n",
    "rootdir = os.path.join(data_dir, scene)\n",
    "scenedir = os.path.join(output_dir, scene)\n",
    "\n",
    "safe_makedir(os.path.join(scenedir))\n",
    "# Load all the SPAD and kinect data\n",
    "spad = load_spad(os.path.join(rootdir, \"spad_20m\", \"data_accum.mat\"))\n",
    "# print(spad.shape)\n",
    "spad_relevant = spad[..., min_depth_bin:max_depth_bin]\n",
    "spad_single_relevant = np.sum(spad_relevant, axis=(0,1))\n",
    "ambient_estimate = np.mean(spad_single_relevant[:ambient_max_depth_bin])\n",
    "\n",
    "# Get ground truth depth\n",
    "gt_idx = np.argmax(spad_relevant, axis=2)\n",
    "gt_r = signal.medfilt(np.fliplr(np.flipud(((gt_idx + min_depth_bin)* bin_width_m).T)), kernel_size=5)\n",
    "mask = (gt_r >= min_depth).astype('float').squeeze()\n",
    "gt_z = r_to_z(gt_r, fc_spad)\n",
    "gt_z = undistort_img(gt_z, fc_spad, pc_spad, rdc_spad, tdc_spad)\n",
    "mask = np.round(undistort_img(mask, fc_spad, pc_spad, rdc_spad, tdc_spad))\n",
    "# Nearest neighbor upsampling to reduce holes in output\n",
    "scale_factor = 2\n",
    "gt_z_up = cv2.resize(gt_z, dsize=(scale_factor*gt_z.shape[0], scale_factor*gt_z.shape[1]),\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "mask_up = cv2.resize(mask, dsize=(scale_factor*mask.shape[0], scale_factor*mask.shape[1]),\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Get RGB and intensity\n",
    "rgb, rgb_cropped, intensity, crop = load_and_crop_kinect(rootdir, kinect_file=\"kinect_finish.mat\")\n",
    "\n",
    "\n",
    "# Project GT depth and mask to RGB image coordinates and crop it.\n",
    "gt_z_proj, mask_proj = project_depth(gt_z_up, mask_up, (rgb.shape[0], rgb.shape[1]),\n",
    "                                     fc_spad*scale_factor, fc_kinect, pc_spad*scale_factor, pc_kinect,\n",
    "                                     RotationOfKinect, TranslationOfKinect/1e3)\n",
    "gt_z_proj_crop = gt_z_proj[crop[0]+offset[0]:crop[1]+offset[0],\n",
    "                           crop[2]+offset[1]:crop[3]+offset[1]]\n",
    "gt_z_proj_crop = signal.medfilt(gt_z_proj_crop, kernel_size=5)\n",
    "# mask_proj_crop = mask_proj[crop[0]+offset[0]:crop[1]+offset[0],\n",
    "#                            crop[2]+offset[1]:crop[3]+offset[1]]\n",
    "mask_proj_crop = (gt_z_proj_crop >= min_depth).astype('float').squeeze()\n",
    "\n",
    "# Process SPAD\n",
    "spad_sid = preprocess_spad(spad_single_relevant, ambient_estimate, min_depth, max_depth, sid_obj)\n",
    "\n",
    "# Initialize with CNN\n",
    "z_init = dorn_predict(dorn_model, rgb_cropped)\n",
    "r_init = z_to_r(z_init, fc_kinect)\n",
    "\n",
    "# Histogram Match\n",
    "weights = intensity\n",
    "r_pred, t = image_histogram_match(r_init, spad_sid, weights, sid_obj)\n",
    "z_pred = r_to_z(r_pred, fc_kinect)\n",
    "\n",
    "# Mean Match\n",
    "med_bin = get_hist_med(spad_sid)\n",
    "hist_med = sid_obj.sid_bin_values[med_bin.astype('int')]\n",
    "r_med_scaled = np.clip(r_init * hist_med/np.median(r_init), a_min=min_depth, a_max=max_depth)\n",
    "z_med_scaled = r_to_z(r_med_scaled, fc_kinect)\n",
    "\n",
    "# Find min and max depth across r and z separately\n",
    "min_r = min(np.min(a) for a in [gt_r, r_init, r_pred, r_med_scaled])\n",
    "max_r = max(np.max(a) for a in [gt_r, r_init, r_pred, r_med_scaled])\n",
    "min_z = min(np.min(a) for a in [gt_z, z_init, z_pred, z_med_scaled, gt_z_proj, gt_z_proj_crop])\n",
    "max_z = max(np.max(a) for a in [gt_z, z_init, z_pred, z_med_scaled, gt_z_proj, gt_z_proj_crop])\n",
    "mins_and_maxes = {\n",
    "    \"min_r\": min_r,\n",
    "    \"max_r\": max_r,\n",
    "    \"min_z\": min_z,\n",
    "    \"max_z\": max_z\n",
    "}\n",
    "\n",
    "# Save stuff\n",
    "np.save(os.path.join(scenedir, \"mins_and_maxes.npy\"), mins_and_maxes)\n",
    "\n",
    "# Save to figures\n",
    "print(\"Saving figures...\")\n",
    "# spad_single_relevant w/ ambient estimate\n",
    "plt.figure()\n",
    "plt.bar(range(len(spad_single_relevant)), spad_single_relevant, log=True)\n",
    "plt.title(\"spad_single_relevant\".format(scene))\n",
    "plt.axhline(y=ambient_estimate, color='r', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(scenedir, \"spad_single_relevant.pdf\"))\n",
    "# gt_r and gt_z and gt_z_proj and gt_z_proj_crop and masks\n",
    "depth_imwrite(gt_r, min_r, max_r, os.path.join(scenedir, \"gt_r\"))\n",
    "depth_imwrite(gt_z, min_z, max_z, os.path.join(scenedir, \"gt_z\"))\n",
    "depth_imwrite(gt_z_proj, min_z, max_z, os.path.join(scenedir, \"gt_z_proj\"))\n",
    "depth_imwrite(gt_z_proj_crop, min_z, max_z, os.path.join(scenedir, \"gt_z_proj_crop\"))\n",
    "depth_imwrite(mask, 0., 1., os.path.join(scenedir, \"mask\"))\n",
    "depth_imwrite(mask_proj, 0., 1., os.path.join(scenedir, \"mask_proj\"))\n",
    "depth_imwrite(mask_proj_crop, 0., 1., os.path.join(scenedir, \"mask_proj_crop\"))\n",
    "depth_imwrite(intensity, 0., 1., os.path.join(scenedir, \"intensity\"))\n",
    "np.save(os.path.join(scenedir, \"crop.npy\"), crop)\n",
    "# spad_sid after preprocessing\n",
    "plt.figure()\n",
    "plt.bar(range(len(spad_sid)), spad_sid, log=True)\n",
    "plt.title(\"spad_sid\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(scenedir, \"spad_sid.pdf\"))\n",
    "# rgb, rgb_cropped, intensity\n",
    "cv2.imwrite(os.path.join(scenedir, \"rgb.png\"), cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(os.path.join(scenedir, \"rgb_cropped.png\"), cv2.cvtColor(rgb_cropped, cv2.COLOR_RGB2BGR))\n",
    "# r_init, z_init, diff_maps\n",
    "depth_imwrite(r_init, min_r, max_r, os.path.join(scenedir, \"r_init\"))\n",
    "depth_imwrite(z_init, min_z, max_z, os.path.join(scenedir, \"z_init\"))\n",
    "# r_pred, z_pred, diff_maps\n",
    "depth_imwrite(r_pred, min_r, max_r, os.path.join(scenedir, \"r_pred\"))\n",
    "depth_imwrite(z_pred, min_z, max_z, os.path.join(scenedir, \"z_pred\"))\n",
    "# r_med_scaled, z_med_scaled, diff_maps\n",
    "depth_imwrite(r_med_scaled, min_r, max_r, os.path.join(scenedir, \"r_med_scaled\"))\n",
    "depth_imwrite(z_med_scaled, min_z, max_z, os.path.join(scenedir, \"z_med_scaled\"))\n",
    "plt.close('all')\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Computing error metrics...\")\n",
    "# z_init\n",
    "# z_init_resized = cv2.resize(z_init, gt_z.shape)\n",
    "init_metrics = get_depth_metrics(torch.from_numpy(z_init).float(),\n",
    "                                 torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                 torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"init_metrics.npy\"), init_metrics)\n",
    "# z_pred\n",
    "# z_pred_resized = cv2.resize(z_pred, gt_z.shape)\n",
    "pred_metrics = get_depth_metrics(torch.from_numpy(z_pred).float(),\n",
    "                                 torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                 torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"pred_metrics.npy\"), pred_metrics)\n",
    "\n",
    "# z_med_scaled\n",
    "# z_med_scaled_resized = cv2.resize(z_med_scaled, gt_z.shape)\n",
    "med_scaled_metrics = get_depth_metrics(torch.from_numpy(z_med_scaled).float(),\n",
    "                                       torch.from_numpy(gt_z_proj_crop).float(),\n",
    "                                       torch.from_numpy(mask_proj_crop).float())\n",
    "np.save(os.path.join(scenedir, \"med_scaled_metrics.npy\"), med_scaled_metrics)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-26T01:08:55.692Z"
    }
   },
   "outputs": [],
   "source": [
    "# DORN figures\n",
    "plt.figure()\n",
    "plt.imshow(rgb_cropped)\n",
    "plt.figure()\n",
    "plt.imshow(gt_z_proj_crop)\n",
    "plt.figure()\n",
    "plt.imshow(z_init)\n",
    "plt.figure()\n",
    "plt.imshow(z_pred)\n",
    "plt.figure()\n",
    "plt.imshow(z_med_scaled)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
