% \paragraph{Depth Imaging}
% Include in intro, don't necessarily need it here.
% Conventional approaches to estimating depth from images include stereo-based
% approaches 
% \begin{itemize}
% 	\item stereo and multiview
% 	\item structured illumination and random patterns (kinect, etc.), active stereo
% 	\item time of flight (continuous wave and pulsed)
% 	\item what we do: like pulsed but much simpler setup; no scanning, no spad array, ...
% \end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Monocular Depth Estimation}
%
Estimating a depth map from a single RGB image has been approached using Markov Random Fields~\cite{Saxena2006}, geometric approaches~\cite{Hoiem2005}, and non-parametric, SIFT-based methods~\cite{Karsch2014}. More recently, deep neural networks have been applied to this problem. For example, Eigen et al.~\cite{Eigen2014} use a multi-scale neural network to
predict depth maps, Godard et al.~\cite{Godard2017} use an unsupervised approach that trains a network using stereo pairs, and Fu et al.~\cite{Fu2018} combine a logarithmic depth discretization scheme with an ordinal regression loss function. Various experiments using different types of encoder networks (\eg ResNet, DenseNet)~\cite{Alhashim2018,Laina2016} have also been employed with some success, as have approaches mixing deep learning with conditional random fields~\cite{Xu2017}, and attention-based approaches~\cite{Hao2018,Xu2018}. Recently, Lasinger et al.~\cite{Lasinger:2019} improved the robustness of monocular depth estimation using cross-dataset transfer.

Despite achieving remarkable success on estimating ordinal depth from a single image, none of these methods are able to resolve inherent scale ambiguity in a principled manner. We introduce a new approach that leverages existing monocular depth estimation networks and disambiguates the output using depth histogram-like measurements obtained from a single, diffused SPAD. Other approaches to disambiguating monocular depth estimation use optimized freeform lenses~\cite{Chang:2019:DeepOptics3D,Wu:2019} or dual-pixel sensors~\cite{Garg:2019}, but these approaches require custom lenses or sensors and specialized image reconstruction methods. In contrast, our approach is potentially compatible with existing camera systems (\eg deployed on current cell phones) and our algorithms could be used in tandem with existing camera ISPs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Depth Imaging and Sensor Fusion with SPADs}
%
Emerging single-photon LiDAR systems use single-photon avalanche diodes (SPADs) to record the time of flight of individual photons. SPAD detectors can be fabricated using standard CMOS processes, but the required picosecond-accurate time-stamping electronics are challenging to miniaturize and fabricate at low cost. For this reason, many single-photon 3D imaging approaches use a single SPAD combined with a raster scanning mechanism~\cite{Kirmani:2014,Lamb2010,Li:2019,pawlikowska2017single}. Unfortunately, this makes it challenging to scan dynamic scenes at high resolution and scanners can also be expensive, difficult to calibrate, and prone to mechanical failure. To reduce the scanning complexity to one dimension, 1D SPAD arrays have been developed~\cite{burri2017linospad,burri2016linospad,OToole2017}, and 2D SPAD arrays are also an active area of research~\cite{Niclass2005,Stoppa2007,Veerappan2011,Zhang2018}. Yet, single-pixel SPADs remain the only viable option for low-cost consumer devices today.

The proposed method uses a single-pixel SPAD and pulsed light source that are diffused across the entire scene instead of aimed at a single point, as with proximity sensors. This unique configuration captures a measurement that closely resembles the depth histogram of the scene. Our sensor fusion algorithm achieves reliable absolute depth estimation by combining the SPAD measurement with the output of a monocular depth estimator using a histogram matching technique. While other recent work also explored RGB-SPAD sensor fusion~\cite{Lindell2018}, the RGB image was primarily used to guide the denoising and upsampling of measurements from a SPAD array.
 
%Previous work (see \cite{Horaud2016} for a survey) has been able to use single-pixel SPADs \cite{Lamb2010} and also 1D LinoSPADs in tandem with various scanning or DMD devices to capture 3D volumes of photon arrivals that can be used to reconstruct depth. Lindell et. al. \cite{Lindell2018} use a LinoSPAD and epipolar scanline and fuse the SPAD data with an RGB image to produce high-quality depth.  Our approach uses a single pixel SPAD but does not require any scanning or DMD mechanism.

%A parallel approach called 3D flash LiDAR uses a laser with an optical diffuser
%as the illumination source and a 2D array of SPADs to capture the 3D volume
%\cite{Stoppa2007, Niclass2005}. Such arrays are capable of reconstructing high
%quality depth but remain relatively low resolution. Other arrays are able to
%achieve higher resolution, but suffer from low fill factor \cite{Veerappan2011} or
%sacrifice per-pixel TDC \cite{Zhang2018}.

% \begin{itemize}
%   \item Scanned single-pixel and 1D arrays, but scanning is hard
%   \item high resolution arrays -> challenging to do TDC
%   \item Individual (non-scanning) SPADs already exist in e.g. iPhoneX, but use
%     is limited to proximity sensors.
%   \item What we do: No array (easier), no scanning (easier), much cheaper,
%     combined with RGB camera to do high-resolution depth imaging, a more complex
%     task.
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{Deep Sensor Fusion}
% Maybe mention in previous section? 
% global hints for super-resolution, colorization, depth estimation 
%
% \begin{itemize}
	% \item colorization
	% \item david's 2018 paper for depth estimation and denoising (see david's 2019 sig paper for related work)
	% \item what we do: slightly different application
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Histogram Matching and Global Hints}
%
Histogram matching is a well-known image processing technique for adjusting an image so that its histogram matches some pre-specified histogram (often derived from another image)~\cite{gonzales1977gray,Gonzalez2008}. Nikolova et al.~\cite{Nikolova2013} use optimization to recover a strict ordering of the image pixels, yielding an exact histogram match. Morovic et al.~\cite{Morovic2002} provide an efficient and precise method for fast histogram matching which supports weighted pixel values. In the image reconstruction space, Swoboda and Schn\"orr~\cite{Swoboda2013} use a histogram to form an image prior based on the Wasserstein distance for image denoising and inpainting. Rother et al.~\cite{Rother2006} use a histogram prior to create an energy function that penalizes foreground segmentations with dissimilar histograms. In a slightly different application area, Zhang et al.~\cite{Zhang2017} train a neural network to produce realistically colorized images given only a black-and-white image and a histogram of global color information.

In our procedure, the diffused SPAD measurements closely resemble a histogram of the depth map where the histogram values are weighted by spatially varying scene reflectances and inverse-square falloff effects. We therefore adapt the algorithm in Morovic et al.~\cite{Morovic2002} in order to accommodate general per-pixel weights during histogram matching.

% \textcolor{red}{Our method is essentially a modified form of the algorithm in \cite{Morovic2002}, modified for our particular use case. Also worth noting is the fact that most algorithms compute histograms from existing images, whereas our method mesaures the depth histogram indirectly using photon arrivals.} Note: this paragraph needs more work. We can say something like ``Inspired by Morovic et al., we do something'' but then we also need to highlight how our method is different. Perhaps concisely summarize how you adapt it for our SPAD model.
%
% \begin{itemize}
%   \item Exact histogram matching paper used in this work
%   \item Wasserstein-based optimization techniques for
%     histogram-based regularization
% \end{itemize}


