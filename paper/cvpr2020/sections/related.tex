% \paragraph{Depth Imaging}
% Include in intro, don't necessarily need it here.
% Conventional approaches to estimating depth from images include stereo-based
% approaches 
% \begin{itemize}
% 	\item stereo and multiview
% 	\item structured illumination and random patterns (kinect, etc.), active stereo
% 	\item time of flight (continuous wave and pulsed)
% 	\item what we do: like pulsed but much simpler setup; no scanning, no spad array, ...
% \end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Monocular Depth Estimation}
%
Estimating a depth map from a single RGB image has been approached using Markov Random Fields~\cite{Saxena2006}, geometric approaches~\cite{Hoiem2005}, and non-parametric, SIFT-based methods~\cite{Karsch2014}. More recently, deep neural networks have been applied to this problem. For example, Eigen et al.~\cite{Eigen2014} use a multi-scale neural network to
predict depth maps, Godard et al.~\cite{Godard2017} use an unsupervised approach that trains a network using stereo pairs, and Fu et al.~\cite{Fu2018} combined a logarithmic depth discretization scheme with an ordinal regression loss function. Various experiments using different types of encoder networks (e.g. ResNet, DenseNet)~\cite{Laina2016,Alhashim2018} have also been employed with some success, as have approaches mixing deep learning with conditional random fields~\cite{Xu2017}, and attention-based approaches~\cite{Xu2018,Hao2018}. Recently, Lasinger et al.~\cite{Lasinger:2019} improved the robustness of monocular depth estimation using cross-dataset transfer.

Despite achieving remarkable success on estimating ordinal depth from a single image, none of these methods are able to resolve inherent scale ambiguity in a principled manner. We introduce a new approach that leverages existing monocular depth estimation networks but disambiguates their output with depth histogram-like measurements obtained from a single, diffused SPAD. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Depth Imaging and Sensor Fusion with SPADs}
%
Emerging single-photon LiDAR systems use single photon avalanche diodes (SPADs) to record the time of flight of individual photons. Whereas SPAD detectors can be fabricated using standard CMOS processes, the required picosecond-accurate time-stamping electronics are challenging to miniaturize and fabricate at low cost. For this reason, many single-photon 3D imaging approaches use a single SPAD combined with a raster scanning mechanism~\cite{Lamb2010,Kirmani:2014,pawlikowska2017single,Li:2019}. Unfortunately, this makes it challenging to scan dynamic scenes at high resolution and scanners can also be expensive, difficult to calibrate, and prone to mechanical failure. To reduce the scanning complexity to one dimension, 1D SPAD arrays have been developed~\cite{burri2016linospad,burri2017linospad,OToole2017}, and 2D SPAD arrays are also an active area of research~\cite{Niclass2005,Stoppa2007,Veerappan2011,Zhang2018}. Yet, single-pixel SPADs remain the only viable option for low cost consumer devices today.

The proposed method uses a single-pixel SPAD, but rather than aiming it at one point in the scene as proximity sensors do, we propose to diffuse it along with the pulsed light source. This is a unique configuration that allows us capture a transient that closely resembles the shape of the depth histogram of the scene. We develop a sensor fusion algorithm to combine the output of a monocular depth estimator and this depth histogram to achieve more reliable absolute depth estimation. While other recent work also explored RGB-SPAD sensor fusion~\cite{Lindell2018}, in that work an intensity image was primarily used to guide a denoising and upsampling step of recorded 2D SPAD array.
 
%Previous work (see \cite{Horaud2016} for a survey) has been able to use single-pixel SPADs \cite{Lamb2010} and also 1D LinoSPADs in tandem with various scanning or DMD devices to capture 3D volumes of photon arrivals that can be used to reconstruct depth. Lindell et. al. \cite{Lindell2018} use a LinoSPAD and epipolar scanline and fuse the SPAD data with an RGB image to produce high-quality depth.  Our approach uses a single pixel SPAD but does not require any scanning or DMD mechanism.

%A parallel approach called 3D flash LiDAR uses a laser with an optical diffuser
%as the illumination source and a 2D array of SPADs to capture the 3D volume
%\cite{Stoppa2007, Niclass2005}. Such arrays are capable of reconstructing high
%quality depth but remain relatively low resolution. Other arrays are able to
%achieve higher resolution, but suffer from low fill factor \cite{Veerappan2011} or
%sacrifice per-pixel TDC \cite{Zhang2018}.

% \begin{itemize}
%   \item Scanned single-pixel and 1D arrays, but scanning is hard
%   \item high resolution arrays -> challenging to do TDC
%   \item Individual (non-scanning) SPADs already exist in e.g. iPhoneX, but use
%     is limited to proximity sensors.
%   \item What we do: No array (easier), no scanning (easier), much cheaper,
%     combined with RGB camera to do high-resolution depth imaging, a more complex
%     task.
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{Deep Sensor Fusion}
% Maybe mention in previous section? 
% global hints for super-resolution, colorization, depth estimation 
%
% \begin{itemize}
	% \item colorization
	% \item david's 2018 paper for depth estimation and denoising (see david's 2019 sig paper for related work)
	% \item what we do: slightly different application
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Histogram Matching and Global Hints}
%
Histogram matching is a well-known image processing technique for adjusting an image so that its histogram matches some pre-specified histogram (often derived from another image)~\cite{gonzales1977gray,Gonzalez2008}. Nikolova et al.~\cite{Nikolova2013} use optimization to recover a strict ordering of the image pixels that allows an exact histogram match to be obtained. Morovic et al.~\cite{Morovic2002} provide a simple and concise method that also achieves an exact histogram match while being very fast. In the image reconstruction space, Swoboda and Schn\"orr~\cite{Swoboda2013} use a histogram to form an image prior based on the Wasserstein distance for image denoising and inpainting. Rother et al.~\cite{Rother2006} use a histogram prior to create an energy function that penalizes foreground segmentations with dissimilar histograms. In a slightly different vein, Zhang et al.~\cite{Zhang2017} train a neural network to produce realistically colorized images given only a black-and-white image and a histogram of global color information.

Because the single SPAD produces a weighted histogram of the depth map, we adapt
the algorithm in Morovic et al. to accommodate general per-pixel
weights, which allows us to compensate for different scene reflectances during
the histogram matching.
% \textcolor{red}{Our method is essentially a modified form of the algorithm in \cite{Morovic2002}, modified for our particular use case. Also worth noting is the fact that most algorithms compute histograms from existing images, whereas our method mesaures the depth histogram indirectly using photon arrivals.} Note: this paragraph needs more work. We can say something like ``Inspired by Morovic et al., we do something'' but then we also need to highlight how our method is different. Perhaps concisely summarize how you adapt it for our SPAD model.
%
% \begin{itemize}
%   \item Exact histogram matching paper used in this work
%   \item Wasserstein-based optimization techniques for
%     histogram-based regularization
% \end{itemize}


