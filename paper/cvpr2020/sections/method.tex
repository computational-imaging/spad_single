In this section, we describe the image formation of a diffused pulsed laser and single-photon avalanche diode (SPAD). We also describe an approach for correcting a depth map generated with a monocular depth estimator to match the global scene information captured by the diffused SPAD.

%In this section, we describe the measurement model for a single-pixel time-of-flight lidar sensor under diffuse, pulsed laser illumination. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Image Formation Model of a Diffused SPAD}

Consider a diffused laser that emits a pulse at time $t = 0$ with time-varying
intensity $g(t)$ illuminating some 3D scene. We parameterize the geometry of the
scene as a distance map $z(x, y)$, where each of the 3D points has also some
unknown reflectivity $\alpha$ at the wavelength of the laser. Ignoring
interreflections of the emitted light within the scene, a single-pixel diffused
SPAD integrates light scattered back from the scene onto the detector as
%
\begin{equation}
	s \left( t \right)= \int_{\Omega_x} \int_{\Omega_y} \frac{\alpha \left( x,y \right)}{z(x,y)^2} \cdot  g \left( t - \frac{2z(x,y)}{c} \right) dx dy ,
	\label{eq:pulse_integral} 
\end{equation}  
%
where $c$ is the speed of light, $\Omega_{x,y}$ is the spatial extent of the
diffused light, and we assume that the light is diffused uniformly over the
scene points. Each time such a light pulse is emitted into the scene and
scattered back to the detector, the single-pixel SPAD time-stamps up to one of
the returning photons with some probability. The process is repeated millions of
times per second with the specific number of emitted pulses being controlled by
the repetition rate of the laser.  Each detected photon arrival event is
discretized into a histogram $h$ of the form
%
\begin{equation}
  h[n] \sim \mathcal{P} \left( \eta \int_{n\Delta t}^{(n+1)\Delta t} \left(f * s \right) \left( t \right)  dt + b \right),	
	\label{eq:spad_measurements}
\end{equation}
%
where $(n\Delta t, (n+1) \Delta t)$ models the $n^\text{th}$ time interval or bin of the
temporal histogram, $\eta$ is the photon detection probability of the SPAD, $f$
is a function that models the temporal uncertainty in the detector, and $b$
represents background detections from ambient light and false positive detections known as \textit{dark
count}. As derived in previous work, the combination of signal and background
can be modeled as an inhomogeneous Poisson process
$\mathcal{P}$~\cite{Kirmani:2014,Shin2015}. Finally, we adopt the term
\textit{transient} for the histogram $h[n]$~\cite{Xin2019}.

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{method.pdf}
  \caption{\textbf{Overview of processing pipeline} The processing pipeline uses
      the input SPAD measurements and an RGB image to produce an accurate depth
      map. The SPAD measurements are pre-processed to adjust for ambient photon
      detections, radiometric falloff factors, and to calibrate the bin widths.
      From the RGB image, an MDE estimates an initial depth map
      and the scene reflectance is estimated. A reflectance-weighted
      depth histogram is compared to the processed SPAD measurements to
      calculate a histogram matching matrix which is used to output the corrected depth map.
  }
  \label{fig:pipeline}
\end{figure}

\subsection{Ambient Rejection and Falloff Correction} Before performing
histogram matching, we apply three pre-processing steps to (1)
remove background counts from the transient, (2) compensate for distance
falloff effects, and (3) re-bin the histogram to improve relative accuracy
with increasing distance. An overview of the processing pipeline, including
these preprocessing steps and the histogram matching procedure is depicted in
Figure~\ref{fig:pipeline}.

In the first step, we remove the background counts from the
transient by initally estimating the average amount of background counts
in each time bin. For nearly all natural scenes, the closest objects to the
camera are a finite distance away, and so the first bins of the SPAD
measurement contain only background counts without any backscattered
signal. We can therefore estimate the
average number of background and noise counts $\hat{b}$ as 
%
\begin{equation}
  \hat b = \frac{1}{N}\sum_{n=0}^N h[n]. 
  \label{eq:ambient_estimate}
\end{equation}
%
where we choose the number of bins $N$ to correspond to time
values before the backscattered signal arrives. 

While simply subtracting $\hat{b}$ from the measurements would remove many of
the background counts, a large number of bins containing only background counts would still
have non-zero values, resulting in a skewed
estimate after applying histogram matching.  Instead, we estimate the temporal
support of histogram bins containing signal photons (\ie the range of depths the
scene) and only subtract $\hat{b}$ from these bins. We assume that other
histogram bins contain only background counts that can be discarded. 

Specifically, we identify the first and last bins that record backscattered signal
photons by locating discontinuities in the recorded counts~\cite{Xin2019}. An initial spike in
the measurements at bin $n_\text{first}$ results from the onset of backscattered signal from the closest
object, and a steep dropoff occurs after bin $n_\text{last}$ after backscattered photons from the
furthest object are recorded. 
We estimate $n_\text{first}$ and $n_\text{last}$ by calculating  
first order differences of the histogram $d[n] = \abs{h[n] - h[n+1]}$. 
For a moderate number of background counts, the variance of $h[n] - h[n+1]$ can be approximated  
as a Gaussian with mean $0$ and variance $2b$, and we identify candidate discontinuities
$\mathcal{E}$ with a threshold on the measured differences:
%
\begin{equation}
  \mathcal{E} = \mset{n}{d[n] > \beta\sqrt{2\hat b}}.
  \label{eq:edge_set}
\end{equation}
We find that $\beta = 5$ yields good results across both simulated and captured
data.

Initial estimates $n'_\text{first}$ and $n'_\text{last}$ are set to the minimum
value in $\mathcal{E}$ and the maximum value, incremented by one bin. 
Then, we refine these estimates by selecting the closest bins that remain above
a threshold $\tau$ such that
\begin{equation}
    \begin{split}
        &\hat n_\text{first}=\min\{n : h[n] > \tau, h[n+1] > \tau,
            \cdots, h[n'_\text{first}] > \tau\}\\
        &\hat n_\text{last}=\max\{n : h[n'_\text{last}] > \tau,
    \cdots, h[n+1] > \tau, h[n] > \tau\}.
    \end{split}
\end{equation}
The remaining ambient counts are discarded by settings the recorded counts to
zero for all bins where $n < n_\text{last}$ and $n > n_\text{last}$.

%Finally, we reject all photons outside of the valid range by
%clamping those bins to 0, and we subtract our ambient estimate from the photons
%within the valid range:
%\begin{equation}
%  h'_{clean}[n] = \begin{cases}
%    0 & n < \hat n_{first} \\
%    \max(h[n] - \hat b, 0) & \hat n_{first} \leq  n \leq \hat n_{last} \\
%    0 & n > \hat n_{last} \\
%  \end{cases}.
%  \label{eq:h_clean}
%\end{equation}

In the second step, we compensate for distance falloff effects by multiplying the histogram
by distance-dependent scaling factor,
\begin{equation}
    h'[n] = h[n] \cdot r_n^2.
  \label{eq:h_scaled}
\end{equation}
Here, $r_n= \paren*{n + \frac12}\paren*{\frac{c\Delta t}{2}}$ is the distance
corresponding to bin $n$, and this radiometric falloff model is consistent with
measurements captured with our hardware prototype.

Last, we re-bin the transient so that the bin widths increase for increasingly
distant objects. We select the Spacing-Increasing Discretization
(SID) method of \cite{Fu2018}, which changes the bin widths according to an  
exponential function, allocating more bins to closer distances and fewer
bins to farther distances for a fixed number of bins. The bin edges $t_i$ are
given by the following equation,
parameterized by the number of bins $K$ and the range of distances $[\ell, u]$: 
\begin{equation}
  t_i = e^{\log(\ell) + \frac{\log(u/\ell) \cdot i}{K}}  \qquad i = 0,\ldots, K.
  \label{eq:sid_bin_edges}
\end{equation}
This rebinning procedure allows us to use a reduced number of bins in the histogram
matching procedure, reducing computation time while maintaining accuracy. For
the simulated results we follow Fu et al.\ and use $K = 140$ bins with $(\ell, u)
= (0.657, 9.972)$~\cite{Fu2018}. The output of the rebinning procedure is the
target histogram $h_\text{target}$ which we use for histogram matching. 

% \begin{itemize}
%   \item Talk about histogram matching in the ideal case, jump straight to intensity 
%   \item Talk about histogram matching in our case, and how it approaches the
%     ideal case. Discuss the following corrections 
%     \begin{itemize}
%       \item Ambient/DC - Use \cite{Xin2019} to justify looking for large edges,
%         then the ambient estimate to get rid of the noise floor.
%       \item Falloff
%     \end{itemize}
%   \item Talk about how the histogram matching works with intensity
%     considerations applied, briefly.
%   \item We don't address jitter or poisson noise.
% \end{itemize}
% \begin{equation}
%   h[n] \sim \mathcal{P}\paren*{\sum_{x,y}\alpha_{x,y}\eta \lambda_{x,y}[n] + b} \label{global_hints}
% \end{equation}
% Given a SPAD with histogram $h$ according to the above equation, we first
% process the SPAD to remove the effects of some of the terms. First, we 


%Neglecting albedo and falloff effects, an ideal detector counting photon events
%from a location $(x,y)$ in the time interval $(n\Delta t, (n+1) \Delta t)$ would record
%
%\begin{equation}
  %\lambda_{x,y}[n] = \int_{n\Delta t}^{(n+1) \Delta t} (f * g)\paren*{t - 2z(x,y)/c} dt \label{single_loc_spad} 
%\end{equation}  
%
%where $c$ is the speed of light, and $f$ is a function that models the temporal uncertainty in the
%detector. Single-photon avalanche diodes (SPADs) are highly sensitive
%photodetectors which are able to record single photon events with high temporal
%precision \cite{Stuff}. Since the event corresponding to the detection of a
%photon can be described with a Bernoulli random variable,
%the total number of accumulated photons in this time interval follows a Poisson
%distribution according to
%
%\begin{equation}
  %h[n] \sim \mathcal{P}\paren*{\sum_{x,y}\alpha_{x,y}\eta \lambda_{x,y}[n] + b} \label{global_hints}
%\end{equation}
%
%where $\alpha_{x,y} = r_{x,y}/z(x,y)^2$ captures the attenuation of the
%photon counts due to the reflectance $r(x,y)$ of the scene and due to the
%inverse square falloff $1/z(x,y)^2$.
%In addition, $\eta$ is the detection probability of a photon
%triggering a SPAD event, and $b = \eta a + d$ is the average number of background detections resulting
%from ambient photons $a$
%and erroneous ``dark count'' events $d$ resulting from noise within the SPAD.
%% \newpage
%% \begin{table*}[htbp]
%%   \begin{center}
  %%   \begin{tabularx}{\linewidth}{*{2}{X}}
  %%     \includegraphics[width=\textwidth/2-5pt]{sections/figures/spad_example/rgb.png} &
  %%     \includegraphics[width=\textwidth/2-5pt]{sections/figures/spad_example/rawdepth.png} \\
  %%     \includegraphics[width=\textwidth/2-5pt]{sections/figures/spad_example/depth_hist.png} &
  %%     \includegraphics[width=\textwidth/2-5pt]{sections/figures/spad_example/spad_hist.png} \\
  %%   \end{tabularx}
  %% \end{center}
  %% \caption{Sample Image. Top Left is the RGB image. Top Right is ground truth
  %%   depth. Bottom Left is Raw ground truth depth histogram. Bottom Right is
  %%   simulated SPAD measurements. Notice how closer depths are magnified and far
  %%   depths are attenuated.}
%% \end{table*}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Monocular depth estimation with global depth hints}
% Given a single RGB image $I(x,y)$ and a vector of photon arrivals $h[n]$
% described by equation \ref{global_hints}, we seek to
% reconstruct the ground truth depth map $z(x,y)$.
% Our method has two parts. First, we \textbf{initialize} our estimate of the depth map from the single RGB
% image via a monocular depth estimator described below. Second, we \textbf{refine} this depth map using
% the captured measurements $h[n]$ via exact histogram matching. 

% \paragraph{Initialization}
% The first step in our method is to produce an initial estimate of ground truth
% depth. Convolutional Neural Networks have been shown to produce accurate, if poorly-scaled, estimates of depth
% from only a single image. We therefore choose to initialize our depth map
% estimate $\hat z^{(0)}(x,y)$ using
% a CNN. However, any depth estimator reliant on only a single
% view may be used for this step. Furthermore, in the larger context of our
% algorithm, it is more important that the network predict the correct ordinal
% relationships between pixels - that is, to predict the correct relative ordering
% of pixels $a$ and $b$, rather than to get all pixels exactly correct.

\subsection{Histogram Matching}
% \begin{algorithm}[H]
%  \caption{Exact Histogram Matching} 
%  \label{alg:ehm}
%  \input{sections/figures/exact_hist_matching_pseudo.tex}
% \end{algorithm}
Histogram matching is a procedure that adjusts pixel values from an input image
so that the image histogram matches a target histogram. We apply this procedure
to match the histogram of an input depth map, obtained from an MDE, to the
post-processed target histogram $h_\text{target}$ from the SPAD. 

The MDE cannot be directly histogram-matched to the target histogram
because the target histogram incorporates the spatially varying reflectance of
the scene. To account for reflectance in the histogram matching procedure,
we use the normalized image color channel closest to the laser wavelength as an
estimate of the reflectance and compute a reflectance-weighted depth histogram
$h_\text{source}$;
instead of incrementing a bin in the depth histogram by one for every pixel in the MDE
at the corresponding depth, we add the estimated reflectance value of the pixel
to the histogram bin. 

We match the histogram $h_{source}$ to $h_{target}$ using the method of
Morovic et al.~\cite{Morovic2002}. The method involves computing a pixel movement
matrix $T$ such that $T[m, n]$ is the fraction of $h_{source}[m]$ that should be
moved to $h_{target}[n]$. The details of this procedure are outlined in
Algorithm~\ref{alg:ehm}. Intuitively, the procedure starts from the first bin of the
source histogram and distributes its contents to the first bins of the target
histogram, with successive source histogram bins being shifted to successive
target bins in sequence.

Finally, we use the movement matrix $T$ to shift the pixels of the MDE depth map
to match the global depth of the target histogram. For a depth map pixel with
depth bin $k$, we select the corrected bin by sampling from the distribution $T[k,
:]/\sum_{n=1}^NT[k,n]$. This sampling procedure handles the
case where a single input depth bin of the MDE is mapped to
multiple output bins~\cite{Morovic2002}.
%
\begin{algorithm}[H]
 \caption{Pixel Movement} 
 \label{alg:ehm}
 \begin{algorithmic}
  \Procedure{FindMovement}{$h_s$ of length $M$, $h_t$ of length $N$} 
    \State Initialize $T$ as an $M \times N$ array of zeros.
    \For{$m$ in $1,\ldots,M$}
      \For{$n$ in $1,\ldots,N$}
        \State $p_s \gets \sum_{i=1}^{n-1} T[m, i]$
        \State $p_t \gets \sum_{i=1}^{m-1} T[i, n]$
        \State $T[m, n] \gets \min(h_s[m] - p_s, h_t[n] - p_t)$
      \EndFor
    \EndFor
    \State \textbf{return} $T$
  \EndProcedure
 \end{algorithmic}
\end{algorithm}
%


%\subsection{Implementation Details}
%For the Monocular Depth Estimator, we use pretrained versions of the
%the Deep Ordinal Regression Network (DORN) \cite{} and the DenseDepth Network.
%The exact histogram matching method is as described in \cite{}.


